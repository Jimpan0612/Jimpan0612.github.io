[
  {
    "objectID": "tex2img.html",
    "href": "tex2img.html",
    "title": "Text-to-Image with Draw Things",
    "section": "",
    "text": "Draw Things is a locally run AI image generation app designed for macOS, making it ideal for users who want to create AI-generated artwork on their Mac. When doing lightweight AI drawing, using Draw Things is simpler and more convenient than using ComfyUI.\nThis section demonstrates the Text-to-Image generation feature of Draw Things, where images are generated by providing positive and negative keywords with respective weights. The resulting images can have vastly different styles due to the selected checkpoint models, along with the additional use of Lora for fine-tuning certain attributes.\n\n\n\n\n\nLayout Sample",
    "crumbs": [
      "AI Art & Animation",
      "Text-to-Image with Draw Things"
    ]
  },
  {
    "objectID": "tex2img.html#introduction",
    "href": "tex2img.html#introduction",
    "title": "Text-to-Image with Draw Things",
    "section": "",
    "text": "Draw Things is a locally run AI image generation app designed for macOS, making it ideal for users who want to create AI-generated artwork on their Mac. When doing lightweight AI drawing, using Draw Things is simpler and more convenient than using ComfyUI.\nThis section demonstrates the Text-to-Image generation feature of Draw Things, where images are generated by providing positive and negative keywords with respective weights. The resulting images can have vastly different styles due to the selected checkpoint models, along with the additional use of Lora for fine-tuning certain attributes.\n\n\n\n\n\nLayout Sample",
    "crumbs": [
      "AI Art & Animation",
      "Text-to-Image with Draw Things"
    ]
  },
  {
    "objectID": "tex2img.html#positive-keywords",
    "href": "tex2img.html#positive-keywords",
    "title": "Text-to-Image with Draw Things",
    "section": "2 Positive Keywords",
    "text": "2 Positive Keywords\nIn this example, the following positive keywords were used to generate the images:\n(detailed eyes:1.3), elf, Beautiful Lighting, (1girl:(Thick thighs:0.8), blue eyes, blonde hair, absurdly long hair, ahoge, eyebrows visible through hair), (real skin), (outdoors:1.3), (alley:1.2), Pastel floral maxi dress, teardrop pearl earrings, beaded bracelet stack, lora:better_scar:1, (better_scar:1.2), scar on nose, (veins:1.21), (burn scar:1.21), (scar on nose:1.21), (scar on arm:1.21), (scar on Shoulder:1.21)",
    "crumbs": [
      "AI Art & Animation",
      "Text-to-Image with Draw Things"
    ]
  },
  {
    "objectID": "tex2img.html#negative-keywords",
    "href": "tex2img.html#negative-keywords",
    "title": "Text-to-Image with Draw Things",
    "section": "3 Negative Keywords",
    "text": "3 Negative Keywords\nNegative keywords help in avoiding unwanted details such as artifacts or incorrect body parts. In this case, the following negative keywords were applied:\nbad-hands-5, SkinPerfection_NegV15, multiple views, blurry, watermark, letterbox, text, see-through",
    "crumbs": [
      "AI Art & Animation",
      "Text-to-Image with Draw Things"
    ]
  },
  {
    "objectID": "tex2img.html#example-images",
    "href": "tex2img.html#example-images",
    "title": "Text-to-Image with Draw Things",
    "section": "4 Example Images",
    "text": "4 Example Images\nBelow are three images generated with the same prompt, showing how the model choice can drastically affect the style and result of the image:\n\n4.1 Example 1: Anime-style Model\n\n\n\nAnime Style\n\n\nThis image uses an anime-style model to generate a character with exaggerated proportions, pastel tones, and vibrant lighting effects.\n\n\n4.2 Example 2: Realistic Model\n\n\n\nRealistic Style\n\n\nA more realistic model produces natural skin tones and textures, with softer lighting and more life-like appearances of hair and clothing.\n\n\n4.3 Example 3: Storybook Model\n\n\n\nStorybook Style\n\n\nThis model aims for a whimsical, storybook-style appearance, with a softer, dream-like quality in the background and character rendering.",
    "crumbs": [
      "AI Art & Animation",
      "Text-to-Image with Draw Things"
    ]
  },
  {
    "objectID": "tex2img.html#influence-of-checkpoint-models",
    "href": "tex2img.html#influence-of-checkpoint-models",
    "title": "Text-to-Image with Draw Things",
    "section": "5 Influence of Checkpoint Models",
    "text": "5 Influence of Checkpoint Models\nThe reason for the vastly different styles among the generated images is the choice of checkpoint models. Each model is pre-trained on different datasets, which leads to its unique understanding of the input keywords. Additionally, Lora is used in this workflow to fine-tune certain attributes like scars and skin textures, further influencing the outcome.",
    "crumbs": [
      "AI Art & Animation",
      "Text-to-Image with Draw Things"
    ]
  },
  {
    "objectID": "2imgbatch_img2vid.html",
    "href": "2imgbatch_img2vid.html",
    "title": "Two Image Batch to Video Creation",
    "section": "",
    "text": "In this workflow, we use the IPAdapter to create an animation by transitioning between two similarly styled images. This method is effective for animations like eye blinking, where subtle differences (such as open and closed eyes) are applied between frames.\nThe process involves configuring AnimateDiff and using upscaling to achieve higher-quality results while optimizing memory usage. The complete workflow can be found below, and you can import the JSON file into ComfyUI by dragging it into the interface.\nDownload the workflow JSON file\n\nEyes Blink Animation Output:\n\n\n\n\nEyes Blink Animation",
    "crumbs": [
      "AI Art & Animation",
      "Two Image Batch to Video Creation"
    ]
  },
  {
    "objectID": "2imgbatch_img2vid.html#introduction",
    "href": "2imgbatch_img2vid.html#introduction",
    "title": "Two Image Batch to Video Creation",
    "section": "",
    "text": "In this workflow, we use the IPAdapter to create an animation by transitioning between two similarly styled images. This method is effective for animations like eye blinking, where subtle differences (such as open and closed eyes) are applied between frames.\nThe process involves configuring AnimateDiff and using upscaling to achieve higher-quality results while optimizing memory usage. The complete workflow can be found below, and you can import the JSON file into ComfyUI by dragging it into the interface.\nDownload the workflow JSON file\n\nEyes Blink Animation Output:\n\n\n\n\nEyes Blink Animation",
    "crumbs": [
      "AI Art & Animation",
      "Two Image Batch to Video Creation"
    ]
  },
  {
    "objectID": "2imgbatch_img2vid.html#workflow-overview",
    "href": "2imgbatch_img2vid.html#workflow-overview",
    "title": "Two Image Batch to Video Creation",
    "section": "2 Workflow Overview",
    "text": "2 Workflow Overview\n\nWorkflow Setup: \n\n\n2.1 Step 1: Image Selection\nStart by providing both positive and negative keywords that describe the video you wish to create. Select two images of the same character with subtle differences. For example, to create a blinking animation, use one image where the character’s eyes are open and another where the eyes are closed.\n\n2 batch images: \nClosed Eyes image : \n\n\n\n2.2 Step 2: IPAdapter and AnimateDiff Configuration\nThe next step is setting up IPAdapter and AnimateDiff. You load both images into the animation workflow and configure the frame rate, loop count, and time distribution between the two images. Adjust the animation length by giving each image a weight based on how long it should be displayed in the animation.\n\n\n2.3 Step 3: Generate Initial Animation\nRun the animation with AnimateDiff and KSampler to produce a transition between the two images. In this case, Image 1 (open eyes) will show for 50% of the duration, and Image 2 (closed eyes) will appear for 50%.\n\n\n2.4 Step 4: Upscaling for Enhanced Quality\nAfter generating the animation, we upscale the latent space using the Upscale Latent By node. This increases the resolution and enhances the details, allowing us to keep the memory usage low while maintaining quality.\n\nUpscaling Process: \n\n\n\n2.5 Step 5: Comparing Results\nThe upscaling process significantly improves the image quality, reducing blurriness and enhancing finer details. Here’s a comparison between the original and upscaled images:\n\nBefore and After Upscale Comparison:",
    "crumbs": [
      "AI Art & Animation",
      "Two Image Batch to Video Creation"
    ]
  },
  {
    "objectID": "2imgbatch_img2vid.html#conclusion",
    "href": "2imgbatch_img2vid.html#conclusion",
    "title": "Two Image Batch to Video Creation",
    "section": "3 Conclusion",
    "text": "3 Conclusion\nBy using the IPAdapter and AnimateDiff workflow, you can smoothly animate transitions between two images. Upscaling the latent space allows for high-quality animations without heavy resource consumption. This method is efficient for creating AI-generated animations like blinking or other subtle movements, as seen in the final output here.",
    "crumbs": [
      "AI Art & Animation",
      "Two Image Batch to Video Creation"
    ]
  },
  {
    "objectID": "6381Lab04.html",
    "href": "6381Lab04.html",
    "title": "Lab 04: Digitizing and Topology",
    "section": "",
    "text": "This lab focuses on digitizing and creating topological rules within ArcGIS. The main tasks involve setting up a digitizing environment, creating and editing feature layers, and applying topological rules to ensure the accuracy and integrity of the digitized data.",
    "crumbs": [
      "ArcGIS",
      "Lab 04: Digitizing and Topology"
    ]
  },
  {
    "objectID": "6381Lab04.html#introduction",
    "href": "6381Lab04.html#introduction",
    "title": "Lab 04: Digitizing and Topology",
    "section": "",
    "text": "This lab focuses on digitizing and creating topological rules within ArcGIS. The main tasks involve setting up a digitizing environment, creating and editing feature layers, and applying topological rules to ensure the accuracy and integrity of the digitized data.",
    "crumbs": [
      "ArcGIS",
      "Lab 04: Digitizing and Topology"
    ]
  },
  {
    "objectID": "6381Lab04.html#objectives",
    "href": "6381Lab04.html#objectives",
    "title": "Lab 04: Digitizing and Topology",
    "section": "2 Objectives",
    "text": "2 Objectives\n\nUnderstand the process of digitizing features using ArcGIS Pro.\nApply topological rules to maintain spatial relationships between digitized features.\nValidate and correct topological errors within the dataset.",
    "crumbs": [
      "ArcGIS",
      "Lab 04: Digitizing and Topology"
    ]
  },
  {
    "objectID": "6381Lab04.html#tasks",
    "href": "6381Lab04.html#tasks",
    "title": "Lab 04: Digitizing and Topology",
    "section": "3 Tasks",
    "text": "3 Tasks\n\n3.1 1. Preparing the Data\n\nStart ArcGIS Pro and create a new map project.\nLoad the provided RectSpring image and add the Lab4AP.gdb to the project.\nInclude the necessary layers (NWI, MNDOT, DNR lakes, and SouthBayArea feature classes).\n\n\n\n3.2 2. Digitizing Upland and Lake Boundaries\n\nUse the RectSpring image to digitize the upland/lake boundary within the SouthBayArea.\nDigitize aquatic vegetation using both the RectSpring and BigMarSum images.\nEnsure the boundaries are accurate by switching between images for better visual cues.\n\n\n\n3.3 3. Creating and Validating Topology\n\nSet up a topology for the digitized layers within the feature dataset.\nDefine the necessary topology rules to prevent overlaps, gaps, and ensure spatial integrity.\nValidate the topology and identify any errors.",
    "crumbs": [
      "ArcGIS",
      "Lab 04: Digitizing and Topology"
    ]
  },
  {
    "objectID": "6381Lab04.html#results",
    "href": "6381Lab04.html#results",
    "title": "Lab 04: Digitizing and Topology",
    "section": "4 Results",
    "text": "4 Results\n\n4.1 Digitized and Validated Topology\nThe following images show the results of the digitizing and topology validation process.\n\n4.1.1 Uplands, Lakes, Aquatic Vegetation, Big Lake by Jim\n\n\n\nUplands, Lakes, Aquatic Vegetation, Big Lake",
    "crumbs": [
      "ArcGIS",
      "Lab 04: Digitizing and Topology"
    ]
  },
  {
    "objectID": "6381Lab04.html#conclusion",
    "href": "6381Lab04.html#conclusion",
    "title": "Lab 04: Digitizing and Topology",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nDigitizing and topology validation are crucial processes in GIS to ensure that spatial data is accurate and reliable. By following proper digitizing techniques and applying topological rules, one can maintain the integrity of spatial relationships in the dataset. This lab provided hands-on experience in setting.",
    "crumbs": [
      "ArcGIS",
      "Lab 04: Digitizing and Topology"
    ]
  },
  {
    "objectID": "6381Lab05.html",
    "href": "6381Lab05.html",
    "title": "Lab 05: Digital Data and Table Operations",
    "section": "",
    "text": "This lab focuses on the use of digital data and performing basic table operations in GIS. It involves manipulating different data sets and creating maps that represent various geographic and population-related data.",
    "crumbs": [
      "ArcGIS",
      "Lab 05: Digital Data and Table Operations"
    ]
  },
  {
    "objectID": "6381Lab05.html#introduction",
    "href": "6381Lab05.html#introduction",
    "title": "Lab 05: Digital Data and Table Operations",
    "section": "",
    "text": "This lab focuses on the use of digital data and performing basic table operations in GIS. It involves manipulating different data sets and creating maps that represent various geographic and population-related data.",
    "crumbs": [
      "ArcGIS",
      "Lab 05: Digital Data and Table Operations"
    ]
  },
  {
    "objectID": "6381Lab05.html#objectives",
    "href": "6381Lab05.html#objectives",
    "title": "Lab 05: Digital Data and Table Operations",
    "section": "2 Objectives",
    "text": "2 Objectives\n\nExplore different types of digital data sets.\nPerform basic table operations in ArcGIS.\nCreate and interpret thematic maps.",
    "crumbs": [
      "ArcGIS",
      "Lab 05: Digital Data and Table Operations"
    ]
  },
  {
    "objectID": "6381Lab05.html#tasks",
    "href": "6381Lab05.html#tasks",
    "title": "Lab 05: Digital Data and Table Operations",
    "section": "3 Tasks",
    "text": "3 Tasks\n\n3.1 1. Kodiak Island Cities\nA map was created using USGS data to identify cities on Kodiak Island, Alaska. The cities were selected and saved as a subset.\n\n\n3.2 2. Population Density Map\nUsing U.S. census data, a population density map was generated, highlighting the varying population densities across different regions.\n\n\n3.3 3. County Population Symbol Map\nA proportional symbol map was created to display county population for the lower 48 U.S. states.\n\n\n3.4 4. Shaded Relief and Hydrography Map\nDigital elevation and hydrological data were utilized to create a shaded-relief map, enhancing the visual representation of the terrain.\n\n\n3.5 5. Wetlands by Size Class\nWetlands data were classified by size, and a map was produced to display the various size classes of wetlands.",
    "crumbs": [
      "ArcGIS",
      "Lab 05: Digital Data and Table Operations"
    ]
  },
  {
    "objectID": "6381Lab05.html#results",
    "href": "6381Lab05.html#results",
    "title": "Lab 05: Digital Data and Table Operations",
    "section": "4 Results",
    "text": "4 Results\n\n4.0.1 Central Minnesota Population\n\n\n\nCentral Minnesota Population\n\n\n\n\n4.0.2 Lower St. Croix Watershed\n\n\n\nLower St. Croix Watershed\n\n\n\n\n4.0.3 Kodiak Island Cities\n\n\n\nKodiak Island Cities\n\n\n\n\n4.0.4 U.S. Census Data\n\n\n\nU.S. Census Data\n\n\n\n\n4.0.5 Stillwater Wetlands by Size\n\n\n\nStillwater Wetlands by Size",
    "crumbs": [
      "ArcGIS",
      "Lab 05: Digital Data and Table Operations"
    ]
  },
  {
    "objectID": "6381Lab05.html#conclusion",
    "href": "6381Lab05.html#conclusion",
    "title": "Lab 05: Digital Data and Table Operations",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nThis lab provided practical experience in handling various digital data sets and performing basic table operations in ArcGIS. Through the creation of multiple thematic maps, key skills in data manipulation and visualization were developed, which are essential for effective spatial analysis.",
    "crumbs": [
      "ArcGIS",
      "Lab 05: Digital Data and Table Operations"
    ]
  },
  {
    "objectID": "6381Lab02.html",
    "href": "6381Lab02.html",
    "title": "Lab 02: Projections in ArcGIS",
    "section": "",
    "text": "In this lab, the goal was to learn about basic methods for map projections in ArcGIS Pro. The task involved creating maps of Minnesota in three different statewide projections, as well as a map of reprojected Minnesota county boundaries with an inset global view. Additionally, the lab involved recording areas and coordinates for various projections and measurements.",
    "crumbs": [
      "ArcGIS",
      "Lab 02: Projections in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab02.html#introduction",
    "href": "6381Lab02.html#introduction",
    "title": "Lab 02: Projections in ArcGIS",
    "section": "",
    "text": "In this lab, the goal was to learn about basic methods for map projections in ArcGIS Pro. The task involved creating maps of Minnesota in three different statewide projections, as well as a map of reprojected Minnesota county boundaries with an inset global view. Additionally, the lab involved recording areas and coordinates for various projections and measurements.",
    "crumbs": [
      "ArcGIS",
      "Lab 02: Projections in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab02.html#objectives",
    "href": "6381Lab02.html#objectives",
    "title": "Lab 02: Projections in ArcGIS",
    "section": "2 Objectives",
    "text": "2 Objectives\n\nUnderstand the differences in map projections and how they affect spatial data.\nCreate maps using different projections: Albers, UTM, and Mercator.\nLearn how to use on-the-fly projections in ArcGIS Pro.\nMeasure distances and coordinates in different projections.",
    "crumbs": [
      "ArcGIS",
      "Lab 02: Projections in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab02.html#tasks",
    "href": "6381Lab02.html#tasks",
    "title": "Lab 02: Projections in ArcGIS",
    "section": "3 Tasks",
    "text": "3 Tasks\n\n3.1 1. Create and Compare Maps\nThree maps were created to compare different projections:\n\nAlbers Projection\nUTM Projection\nMercator Projection\n\nThese maps were then analyzed to understand how the projections affect the shape and measurements within the state of Minnesota.\n\n\n3.2 2. Measure Distances\nUsing the measure tool in ArcGIS Pro, distances between specific points were measured in each of the projections. For example, the distance from the northeastern-most point of Minnesota to the southwestern-most point was calculated in kilometers for all three projections.\n\n\n3.3 3. Record Coordinates\nCoordinates for the northeast corner of Ramsey County were recorded in three projections: Albers, UTM, and Custom Mercator. This step highlighted how different projections can result in different coordinate values for the same geographic location.",
    "crumbs": [
      "ArcGIS",
      "Lab 02: Projections in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab02.html#results",
    "href": "6381Lab02.html#results",
    "title": "Lab 02: Projections in ArcGIS",
    "section": "4 Results",
    "text": "4 Results\n\n4.1 Distance Across Minnesota\n\nAlbers Projection: 738.38 km\nUTM Zone 15N: 739.11 km\nCustom Mercator: 1059.32 km\n\n\n\n4.2 Coordinates of Northeast Corner of Ramsey County\n\n\n\nProjection\nX-Coordinate\nY-Coordinate\n\n\n\n\nAlbers (Meters)\n237015.86E\n2463303.93N\n\n\nUTM Zone 15 (Meters)\n501167.40E\n4996740.42N\n\n\nCustom Mercator\n10351044.86W\n5610717.55N\n\n\n\n\n\n4.3 Final Maps\n\n4.3.1 Comparison of Three Map Projections\n\n\n\nCompare of Three Map Projections\n\n\n\n\n4.3.2 Minnesota Counties - UTM Projection\n\n\n\nMinnesota Counties - UTM Projection",
    "crumbs": [
      "ArcGIS",
      "Lab 02: Projections in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab02.html#conclusion",
    "href": "6381Lab02.html#conclusion",
    "title": "Lab 02: Projections in ArcGIS",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nThis lab provided valuable insights into the importance of map projections in GIS. By working with different projections, it became clear how much projections can impact spatial data, particularly in terms of shape and distance measurements. Understanding and correctly applying map projections is crucial for any spatial analysis in GIS.",
    "crumbs": [
      "ArcGIS",
      "Lab 02: Projections in ArcGIS"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "If you would like to learn more about my professional experience and skills, feel free to download my CV below:\nDownload My CV"
  },
  {
    "objectID": "about.html#download-my-cv",
    "href": "about.html#download-my-cv",
    "title": "About",
    "section": "",
    "text": "If you would like to learn more about my professional experience and skills, feel free to download my CV below:\nDownload My CV"
  },
  {
    "objectID": "img2vid.html",
    "href": "img2vid.html",
    "title": "Mix Image to Video Creation",
    "section": "",
    "text": "In this workflow, we combine three different images: a girl, rain, and blue flame, filter the content through a Mask, and use IPAdapter combined with AnimateDiff to create an animation of a dragon girl casting a spell in the rain. This workflow demonstrates how changing the motion scale affects the movement of different elements in the scene.\nFor example, at a lower motion scale of 0.8, the rain and fire elements remain static, while at a higher scale of 1.4, the background becomes distorted, intensifying the animation.\nThe complete workflow file can be found below for reference, and it can be imported into ComfyUI for further adjustments.\nDownload the workflow JSON file\n\nCasting Spell Animation Output1:\n\n\n\n\nExample 1\n\n\n\nCasting Spell Animation Output2:\n\n\n\n\nExample 2",
    "crumbs": [
      "AI Art & Animation",
      "Mix Image to Video Creation"
    ]
  },
  {
    "objectID": "img2vid.html#introduction",
    "href": "img2vid.html#introduction",
    "title": "Mix Image to Video Creation",
    "section": "",
    "text": "In this workflow, we combine three different images: a girl, rain, and blue flame, filter the content through a Mask, and use IPAdapter combined with AnimateDiff to create an animation of a dragon girl casting a spell in the rain. This workflow demonstrates how changing the motion scale affects the movement of different elements in the scene.\nFor example, at a lower motion scale of 0.8, the rain and fire elements remain static, while at a higher scale of 1.4, the background becomes distorted, intensifying the animation.\nThe complete workflow file can be found below for reference, and it can be imported into ComfyUI for further adjustments.\nDownload the workflow JSON file\n\nCasting Spell Animation Output1:\n\n\n\n\nExample 1\n\n\n\nCasting Spell Animation Output2:\n\n\n\n\nExample 2",
    "crumbs": [
      "AI Art & Animation",
      "Mix Image to Video Creation"
    ]
  },
  {
    "objectID": "img2vid.html#motion-scale-examples",
    "href": "img2vid.html#motion-scale-examples",
    "title": "Mix Image to Video Creation",
    "section": "2 Motion Scale Examples",
    "text": "2 Motion Scale Examples\nThe following examples show how different motion scales impact the animation:\n\nMotion Scale 0.8: The rain and fire remain static. This scale is suitable for less dynamic movement scenes.\n\n\nVideo\nMotion Scale 0.8\n\n\nMotion Scale 1.4: This introduces background distortion, adding a more dynamic and intense movement.\n\n\nVideo\nMotion Scale 1.4",
    "crumbs": [
      "AI Art & Animation",
      "Mix Image to Video Creation"
    ]
  },
  {
    "objectID": "img2vid.html#workflow-overview",
    "href": "img2vid.html#workflow-overview",
    "title": "Mix Image to Video Creation",
    "section": "3 Workflow Overview",
    "text": "3 Workflow Overview\n\nWorkflow Setup: \n\n\n3.1 Step 1: Image Selection\nStart by providing both positive and negative keywords that describe the video you wish to create. Select the three primary images: the girl, rain, and blue flame, that will be used in the animation.\n\nThree primary images: \n\n\n\n3.2 Step 2: Create Mask\nApply a Mask to filter the necessary elements of each image for precise animation control. In this workflow, the mask is used to isolate and control different parts of the image, such as the background and the character, to allow for distinct animation effects.\n\nCreating the Mask: After generating the initial image, the mask is created by removing or painting over the areas where the character is present. This involves erasing or blacking out the parts of the image where the character appears. By doing so, the remaining elements (such as the rain and fire) can be controlled separately in the animation, while the masked-out character remains unaffected. This mask ensures that only the intended elements are animated, adding precision to the final video.\nMask Example: \n\nThis approach provides greater flexibility in fine-tuning the animation, allowing you to focus on specific elements while maintaining control over the overall scene.\n\n\n3.3 Step 3: IPAdapter and AnimateDiff Configuration\nIn the IPAdapter here, you can change the weight and weight type of each image, and set the time points when they appear in the animation. For example, in this workflow, the weight type of the images is set to ease in, which allows for a smooth transition at the beginning of the animation.\nAt the same time, the appearance time of the flame is set between 0.3 and 0.9 of the overall animation duration, which makes the flame appear in the middle of the sequence, creating the effect of casting a fire spell. This configuration helps to synchronize the animation’s visual elements for a more dynamic and immersive result.\n\n\n3.4 Step 4: Motion Scale and Batch Size Configuration\nAdjusting the motion scale and batch size parameters allows fine-tuning of the animation. The motion scale directly impacts how much movement or distortion is applied to the elements in the scene, while the batch size controls the number of frames rendered simultaneously.\n\nMotion Scale: As the motion scale increases, the intensity of the animation also increases. For example, at a lower motion scale (e.g., 0.8), elements like rain and fire remain mostly static, adding subtle animation to the scene. As the motion scale increases (e.g., 1.4), these elements begin to move more dynamically, with greater intensity, and the background may become distorted, creating a more dramatic effect. This allows you to control the level of action or motion depending on your desired output.\nBatch Size: The batch size parameter determines how many frames are rendered in each pass. In this workflow, it also dictates the total number of frames in the animation. A larger batch size results in more frames being generated at once, which can be helpful for smoother animation but may increase memory consumption. Conversely, a smaller batch size can reduce memory load but might produce a more segmented animation. In this example, a batch size of 16 was used to balance performance and smoothness.\nMotion Scale & Batch Size Example: \n\nBy adjusting these parameters, you can fine-tune the movement and animation strength while managing performance and rendering time.\n\n\n3.5 Step 5: Upscaling for Enhanced Quality\nUse the Upscale process to improve the resolution and visual quality of the final animation.\n\nBefore and After Upscale Comparison:",
    "crumbs": [
      "AI Art & Animation",
      "Mix Image to Video Creation"
    ]
  },
  {
    "objectID": "img2vid.html#conclusion",
    "href": "img2vid.html#conclusion",
    "title": "Mix Image to Video Creation",
    "section": "4 Conclusion",
    "text": "4 Conclusion\nThis workflow showcases the flexibility and power of combining IPAdapter with AnimateDiff to create dynamic animations by transitioning between multiple images with various motion scales and batch sizes. By fine-tuning parameters such as motion scale, batch size, and using masks, you can achieve precise control over different elements in the animation, such as the movement of rain and fire.\nThe results demonstrate that subtle changes in the motion scale can significantly impact the animation intensity, from static background elements to more dynamic and dramatic effects. This workflow is ideal for creating captivating visuals, especially when integrating multiple visual components like characters and environmental effects.\nExperimenting with different configurations can help optimize both the visual output and performance, allowing you to create animations that align perfectly with your creative vision.",
    "crumbs": [
      "AI Art & Animation",
      "Mix Image to Video Creation"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jim Pan’s Knowledge Hub",
    "section": "",
    "text": "Updated AI Art & Animation section.\n\n\n\n\n\nAdded AI Art & Animation section.\nAdded Lab01~10 to ArcGIS section.\nUpdated sidebar in ArcGIS section.\n\n\n\n\n\nAdded a new sidebar to the website.\nImproved the color scheme for better readability.\nUpdated the footer with new social media links.\n\n\n\n\n\nUpdated CV and about me.\nAdded logo in nav bar.\n\n\n\n\n\nAdded back to top function.\nIntegrated GitHub and LinkedIn icons in the navigation bar.\nAdded dark mode.\n\n\n\n\n\nAdded Updated Log.\nUpdated GitHub SSH URL repo.\nAdded section for ArcGIS labs."
  },
  {
    "objectID": "index.html#update-log",
    "href": "index.html#update-log",
    "title": "Jim Pan’s Knowledge Hub",
    "section": "",
    "text": "Updated AI Art & Animation section.\n\n\n\n\n\nAdded AI Art & Animation section.\nAdded Lab01~10 to ArcGIS section.\nUpdated sidebar in ArcGIS section.\n\n\n\n\n\nAdded a new sidebar to the website.\nImproved the color scheme for better readability.\nUpdated the footer with new social media links.\n\n\n\n\n\nUpdated CV and about me.\nAdded logo in nav bar.\n\n\n\n\n\nAdded back to top function.\nIntegrated GitHub and LinkedIn icons in the navigation bar.\nAdded dark mode.\n\n\n\n\n\nAdded Updated Log.\nUpdated GitHub SSH URL repo.\nAdded section for ArcGIS labs."
  },
  {
    "objectID": "index.html#this-is-the-page-for-me-to-test-functions.",
    "href": "index.html#this-is-the-page-for-me-to-test-functions.",
    "title": "Jim Pan’s Knowledge Hub",
    "section": "2 This is the page for me to test functions.",
    "text": "2 This is the page for me to test functions.\n\\(y = \\alpha+\\beta{x}^2\\)\n\npar(family = \"sans\")\nplot(iris, pch = 20, cex = .75, col = \"cyan\")\n\n\n\n\n\n\n\n\n\n \n\nplot(Titanic)\n\n\n\n\n\n\n\n\n\n\nHeader\n\n\n&lt;h4 class=\"card-title\"&gt;Is it working?&lt;/h4&gt;\n&lt;p class=\"card-text\"&gt;Some quick example text to build on the card title and make up the bulk of the card's content.&lt;/p&gt;\n\n\n\n\nHeader\n\n\n&lt;h4 class=\"card-title\"&gt;Secondary card title&lt;/h4&gt;\n&lt;p class=\"card-text\"&gt;Some quick example text to build on the card title and make up the bulk of the card's content.&lt;/p&gt;\n\n\n\n\nHeader\n\n\n&lt;h4 class=\"card-title\"&gt;Success card title&lt;/h4&gt;\n&lt;p class=\"card-text\"&gt;Some quick example text to build on the card title and make up the bulk of the card's content.&lt;/p&gt;"
  },
  {
    "objectID": "assign02.html",
    "href": "assign02.html",
    "title": "Jimpan's Knowledge Hub",
    "section": "",
    "text": "You have come to the wasteland of knowledge, which will be updated soon.\n\n\n\n Back to top",
    "crumbs": [
      "assign02.html"
    ]
  },
  {
    "objectID": "6381Lab09.html",
    "href": "6381Lab09.html",
    "title": "Lab 09: Raster Analysis",
    "section": "",
    "text": "This lab focuses on spatial analysis and modeling using raster data. The goal is to estimate access costs across a landscape based on factors like slope and distance to roads. The process includes raster resampling, combining DEMs, filtering data, and creating cost surfaces. The lab also includes a project on correcting DEMs and generating hillshade maps.",
    "crumbs": [
      "ArcGIS",
      "Lab 09: Raster Analysis"
    ]
  },
  {
    "objectID": "6381Lab09.html#introduction",
    "href": "6381Lab09.html#introduction",
    "title": "Lab 09: Raster Analysis",
    "section": "",
    "text": "This lab focuses on spatial analysis and modeling using raster data. The goal is to estimate access costs across a landscape based on factors like slope and distance to roads. The process includes raster resampling, combining DEMs, filtering data, and creating cost surfaces. The lab also includes a project on correcting DEMs and generating hillshade maps.",
    "crumbs": [
      "ArcGIS",
      "Lab 09: Raster Analysis"
    ]
  },
  {
    "objectID": "6381Lab09.html#objectives",
    "href": "6381Lab09.html#objectives",
    "title": "Lab 09: Raster Analysis",
    "section": "2 Objectives",
    "text": "2 Objectives\n\nLearn to mosaic raster data with different resolutions.\nApply filtering techniques to correct noisy DEM data.\nDevelop cost surfaces using slope and distance factors.\nUse raster calculator for advanced spatial analysis.",
    "crumbs": [
      "ArcGIS",
      "Lab 09: Raster Analysis"
    ]
  },
  {
    "objectID": "6381Lab09.html#tasks",
    "href": "6381Lab09.html#tasks",
    "title": "Lab 09: Raster Analysis",
    "section": "3 Tasks",
    "text": "3 Tasks\n\n3.1 1. Mosaic DEMs and Generate Hillshade\n\nCombine Valley3 and Valley9 DEMs, and generate hillshade maps for both.\nResample Valley9 DEM to match Valley3’s 3-meter resolution.\nCombine the two DEMs into a single dataset using raster calculator.\n\n\n\n3.2 2. Correct DEM Artifacts Using Filters\n\nApply a low-pass filter to the Shasta DEM to correct data spikes and pits.\nGenerate a new hillshade map to visualize the corrections.\nSubtract the filtered DEM from the original DEM to isolate errors, then replace erroneous cells using raster calculator.\n\n\n\n3.3 3. Develop a Cost Surface\n\nCalculate slope from DulNorthDEM and apply an exponential cost formula.\nGenerate a distance raster using the Euclidean Distance tool.\nCombine slope and distance costs into a total cost surface, applying a threshold to focus on areas under $25,000.\n\n\n\n3.4 4. Reclassification and Final Cost Calculation\n\nReclassify the total cost surface to focus on areas below $25,000.\nMultiply the reclassified raster by the total cost surface to isolate areas within budget.",
    "crumbs": [
      "ArcGIS",
      "Lab 09: Raster Analysis"
    ]
  },
  {
    "objectID": "6381Lab09.html#results",
    "href": "6381Lab09.html#results",
    "title": "Lab 09: Raster Analysis",
    "section": "4 Results",
    "text": "4 Results\n\n4.1 Combined DEM Hillshade\n\n\n\nCombined DEM Hillshade\n\n\n\n\n4.2 Filtered Shasta DEM Hillshade\n\n\n\nFiltered Shasta DEM Hillshade",
    "crumbs": [
      "ArcGIS",
      "Lab 09: Raster Analysis"
    ]
  },
  {
    "objectID": "6381Lab09.html#conclusion",
    "href": "6381Lab09.html#conclusion",
    "title": "Lab 09: Raster Analysis",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nThis lab provided hands-on experience with advanced raster data processing techniques. The tasks included data resampling, DEM correction using filters, and cost surface generation. These techniques are crucial for spatial analysis in GIS, enabling more accurate modeling and decision-making based on geographic data.",
    "crumbs": [
      "ArcGIS",
      "Lab 09: Raster Analysis"
    ]
  },
  {
    "objectID": "Lab01.html",
    "href": "Lab01.html",
    "title": "EPPS 6302: Lab01",
    "section": "",
    "text": "x &lt;- c(1,3,2,5)\nx\n\n[1] 1 3 2 5\n\nx = c(1,6,2)\nx\n\n[1] 1 6 2\n\ny = c(1,4,3)\n\n\n\n\n\nlength(x)  # What does length() do?\n\n[1] 3\n\nlength(y)\n\n[1] 3\n\n\n\n\n\n\nx+y\n\n[1]  2 10  5\n\nls() # List objects in the environment\n\n[1] \"x\" \"y\"\n\nrm(x,y) # Remove objects\nls()\n\ncharacter(0)\n\nrm(list=ls()) # Danger! What does this do?  Not recommended!\n\n\n\n\n\n?matrix\nx=matrix(data=c(1,2,3,4), nrow=2, ncol=2) # Create a 2x2 matrix object\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx=matrix(c(1,2,3,4),2,2)\nmatrix(c(1,2,3,4),2,2,byrow=TRUE) # What about byrow=F?\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\nsqrt(x) # What does x look like?\n\n         [,1]     [,2]\n[1,] 1.000000 1.732051\n[2,] 1.414214 2.000000\n\nx^2\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\nx=rnorm(50) # Generate a vector of 50 numbers using the rnorm() function\n\ny=x+rnorm(50,mean=50,sd=.1) # What does rnorm(50,mean=50,sd=.1) generate?\n\ncor(x,y) # Correlation of x and y\n\n[1] 0.9948302\n\nset.seed(1303) # Set the seed for Random Number Generator (RNG) to generate values that are reproducible.\nrnorm(50)\n\n [1] -1.1439763145  1.3421293656  2.1853904757  0.5363925179  0.0631929665\n [6]  0.5022344825 -0.0004167247  0.5658198405 -0.5725226890 -1.1102250073\n[11] -0.0486871234 -0.6956562176  0.8289174803  0.2066528551 -0.2356745091\n[16] -0.5563104914 -0.3647543571  0.8623550343 -0.6307715354  0.3136021252\n[21] -0.9314953177  0.8238676185  0.5233707021  0.7069214120  0.4202043256\n[26] -0.2690521547 -1.5103172999 -0.6902124766 -0.1434719524 -1.0135274099\n[31]  1.5732737361  0.0127465055  0.8726470499  0.4220661905 -0.0188157917\n[36]  2.6157489689 -0.6931401748 -0.2663217810 -0.7206364412  1.3677342065\n[41]  0.2640073322  0.6321868074 -1.3306509858  0.0268888182  1.0406363208\n[46]  1.3120237985 -0.0300020767 -0.2500257125  0.0234144857  1.6598706557\n\nset.seed(3) # Try different seeds?\ny=rnorm(100)\n\n\n\n\n\nmean(y)\n\n[1] 0.01103557\n\nvar(y)\n\n[1] 0.7328675\n\nsqrt(var(y))\n\n[1] 0.8560768\n\nsd(y)\n\n[1] 0.8560768\n\n\n\n\n\n\nx=rnorm(100)\ny=rnorm(100)\nplot(x,y, pch=20, col = \"blue\") # Scatterplot for two numeric variables by default\n\n\n\n\n\n\n\nplot(x,y, pch=20, col = \"blue\",xlab=\"this is the x-axis\",ylab=\"this is the y-axis\",main=\"Plot of X vs Y\") # Add labels\n\n\n\n\n\n\n\npdf(\"Figure01.pdf\") # Save as pdf, add a path or it will be stored on the project directory\nplot(x,y,pch=20, col=\"forestgreen\") # Try different colors?\ndev.off() # Close the file using the dev.off function\n\nquartz_off_screen \n                2 \n\nx=seq(1,10) # Same as x=c(1:10)\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=seq(-pi,pi,length=50)\ny=x",
    "crumbs": [
      "EPPS 6302: Lab01"
    ]
  },
  {
    "objectID": "Lab01.html#create-object-using-the-assignment-operator--",
    "href": "Lab01.html#create-object-using-the-assignment-operator--",
    "title": "EPPS 6302: Lab01",
    "section": "",
    "text": "x &lt;- c(1,3,2,5)\nx\n\n[1] 1 3 2 5\n\nx = c(1,6,2)\nx\n\n[1] 1 6 2\n\ny = c(1,4,3)",
    "crumbs": [
      "EPPS 6302: Lab01"
    ]
  },
  {
    "objectID": "Lab01.html#using-function",
    "href": "Lab01.html#using-function",
    "title": "EPPS 6302: Lab01",
    "section": "",
    "text": "length(x)  # What does length() do?\n\n[1] 3\n\nlength(y)\n\n[1] 3",
    "crumbs": [
      "EPPS 6302: Lab01"
    ]
  },
  {
    "objectID": "Lab01.html#using---operators",
    "href": "Lab01.html#using---operators",
    "title": "EPPS 6302: Lab01",
    "section": "",
    "text": "x+y\n\n[1]  2 10  5\n\nls() # List objects in the environment\n\n[1] \"x\" \"y\"\n\nrm(x,y) # Remove objects\nls()\n\ncharacter(0)\n\nrm(list=ls()) # Danger! What does this do?  Not recommended!",
    "crumbs": [
      "EPPS 6302: Lab01"
    ]
  },
  {
    "objectID": "Lab01.html#matrix-operations",
    "href": "Lab01.html#matrix-operations",
    "title": "EPPS 6302: Lab01",
    "section": "",
    "text": "?matrix\nx=matrix(data=c(1,2,3,4), nrow=2, ncol=2) # Create a 2x2 matrix object\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx=matrix(c(1,2,3,4),2,2)\nmatrix(c(1,2,3,4),2,2,byrow=TRUE) # What about byrow=F?\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\nsqrt(x) # What does x look like?\n\n         [,1]     [,2]\n[1,] 1.000000 1.732051\n[2,] 1.414214 2.000000\n\nx^2\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\nx=rnorm(50) # Generate a vector of 50 numbers using the rnorm() function\n\ny=x+rnorm(50,mean=50,sd=.1) # What does rnorm(50,mean=50,sd=.1) generate?\n\ncor(x,y) # Correlation of x and y\n\n[1] 0.9948302\n\nset.seed(1303) # Set the seed for Random Number Generator (RNG) to generate values that are reproducible.\nrnorm(50)\n\n [1] -1.1439763145  1.3421293656  2.1853904757  0.5363925179  0.0631929665\n [6]  0.5022344825 -0.0004167247  0.5658198405 -0.5725226890 -1.1102250073\n[11] -0.0486871234 -0.6956562176  0.8289174803  0.2066528551 -0.2356745091\n[16] -0.5563104914 -0.3647543571  0.8623550343 -0.6307715354  0.3136021252\n[21] -0.9314953177  0.8238676185  0.5233707021  0.7069214120  0.4202043256\n[26] -0.2690521547 -1.5103172999 -0.6902124766 -0.1434719524 -1.0135274099\n[31]  1.5732737361  0.0127465055  0.8726470499  0.4220661905 -0.0188157917\n[36]  2.6157489689 -0.6931401748 -0.2663217810 -0.7206364412  1.3677342065\n[41]  0.2640073322  0.6321868074 -1.3306509858  0.0268888182  1.0406363208\n[46]  1.3120237985 -0.0300020767 -0.2500257125  0.0234144857  1.6598706557\n\nset.seed(3) # Try different seeds?\ny=rnorm(100)",
    "crumbs": [
      "EPPS 6302: Lab01"
    ]
  },
  {
    "objectID": "Lab01.html#simple-descriptive-statistics",
    "href": "Lab01.html#simple-descriptive-statistics",
    "title": "EPPS 6302: Lab01",
    "section": "",
    "text": "mean(y)\n\n[1] 0.01103557\n\nvar(y)\n\n[1] 0.7328675\n\nsqrt(var(y))\n\n[1] 0.8560768\n\nsd(y)\n\n[1] 0.8560768",
    "crumbs": [
      "EPPS 6302: Lab01"
    ]
  },
  {
    "objectID": "Lab01.html#graphics-using-r-graphics-without-packages",
    "href": "Lab01.html#graphics-using-r-graphics-without-packages",
    "title": "EPPS 6302: Lab01",
    "section": "",
    "text": "x=rnorm(100)\ny=rnorm(100)\nplot(x,y, pch=20, col = \"blue\") # Scatterplot for two numeric variables by default\n\n\n\n\n\n\n\nplot(x,y, pch=20, col = \"blue\",xlab=\"this is the x-axis\",ylab=\"this is the y-axis\",main=\"Plot of X vs Y\") # Add labels\n\n\n\n\n\n\n\npdf(\"Figure01.pdf\") # Save as pdf, add a path or it will be stored on the project directory\nplot(x,y,pch=20, col=\"forestgreen\") # Try different colors?\ndev.off() # Close the file using the dev.off function\n\nquartz_off_screen \n                2 \n\nx=seq(1,10) # Same as x=c(1:10)\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=seq(-pi,pi,length=50)\ny=x",
    "crumbs": [
      "EPPS 6302: Lab01"
    ]
  },
  {
    "objectID": "Lab03.html",
    "href": "Lab03.html",
    "title": "EPPS 6323: Lab03",
    "section": "",
    "text": "1 R Programming (EDA)\n(Adapted from Stackoverflow examples) (Objectives: Use plotly, reshape packages, interactive visualization)\n\nlibrary(tidyverse)\nlibrary(plotly)\ndata(iris)\nattach(iris)\n# Generate plot on three quantitative variables\niris_plot &lt;- plot_ly(iris,\n                     x = Sepal.Length,\n                     y = Sepal.Width,\n                     z = Petal.Length,\n                     type = \"scatter3d\",\n                     mode = \"markers\",\n                     size = 0.02)\niris_plot\n\n\n\n\n# Regression object\n\npetal_lm &lt;- lm(Petal.Length ~ 0 + Sepal.Length + Sepal.Width,\n               data = iris)\nlibrary(reshape2)\n\n#load data\n\npetal_lm &lt;- lm(Petal.Length ~ 0 + Sepal.Length + Sepal.Width,data = iris)\n\n# Setting resolution parameter\ngraph_reso &lt;- 0.05\n\n#Setup Axis\naxis_x &lt;- seq(min(iris$Sepal.Length), max(iris$Sepal.Length), by = graph_reso)\naxis_y &lt;- seq(min(iris$Sepal.Width), max(iris$Sepal.Width), by = graph_reso)\n\n# Regression surface\n# Rearranging data for plotting\npetal_lm_surface &lt;- expand.grid(Sepal.Length = axis_x,Sepal.Width = axis_y,KEEP.OUT.ATTRS = F)\npetal_lm_surface$Petal.Length &lt;- predict.lm(petal_lm, newdata = petal_lm_surface)\npetal_lm_surface &lt;- acast(petal_lm_surface, Sepal.Width ~ Sepal.Length, value.var = \"Petal.Length\")\nhcolors=c(\"orange\",\"blue\",\"green\")[iris$Species]\niris_plot &lt;- plot_ly(iris,\n                     x = ~Sepal.Length,\n                     y = ~Sepal.Width,\n                     z = ~Petal.Length,\n                     text = Species,\n                     type = \"scatter3d\",\n                     mode = \"markers\",\n                     marker = list(color = hcolors),\n                     size=0.02)\n# Add surface\niris_plot &lt;- add_trace(p = iris_plot,\n                       z = petal_lm_surface,\n                       x = axis_x,\n                       y = axis_y,\n                       type = \"surface\",mode = \"markers\",\n                       marker = list(color = hcolors))\niris_plot\n\n\n\n\n\n\n\n2 Regression object\n\npetal_lm &lt;- lm(Petal.Length ~ 0 + Sepal.Length + Sepal.Width, \n               data = iris)\n\n\n\n\n\n Back to top",
    "crumbs": [
      "EPPS 6323: Lab03"
    ]
  },
  {
    "objectID": "Lab02.html",
    "href": "Lab02.html",
    "title": "EPPS 6323: Lab02",
    "section": "",
    "text": "(Adapted from ISLR Chapter 3 Lab: Introduction to R)\n\n\n\nA=matrix(1:16,4,4)\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\nA[2,3]\n\n[1] 10\n\nA[c(1,3),c(2,4)]\n\n     [,1] [,2]\n[1,]    5   13\n[2,]    7   15\n\nA[1:3,2:4]\n\n     [,1] [,2] [,3]\n[1,]    5    9   13\n[2,]    6   10   14\n[3,]    7   11   15\n\nA[1:2,]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n\nA[,1:2]\n\n     [,1] [,2]\n[1,]    1    5\n[2,]    2    6\n[3,]    3    7\n[4,]    4    8\n\nA[1,]\n\n[1]  1  5  9 13\n\nA[-c(1,3),]\n\n     [,1] [,2] [,3] [,4]\n[1,]    2    6   10   14\n[2,]    4    8   12   16\n\nA[-c(1,3),-c(1,3,4)]\n\n[1] 6 8\n\ndim(A)\n\n[1] 4 4\n\n\n\n\n\n\nAuto=read.table(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.data\")\n# fix(Auto) # Starting the X11 R data editor\nAuto=read.table(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.data\",header=T,na.strings=\"?\")\n# fix(Auto)\nAuto=read.csv(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.csv\",header=T,na.strings=\"?\")\n# fix(Auto)\ndim(Auto)\n\n[1] 397   9\n\nAuto[1:4,]\n\n  mpg cylinders displacement horsepower weight acceleration year origin\n1  18         8          307        130   3504         12.0   70      1\n2  15         8          350        165   3693         11.5   70      1\n3  18         8          318        150   3436         11.0   70      1\n4  16         8          304        150   3433         12.0   70      1\n                       name\n1 chevrolet chevelle malibu\n2         buick skylark 320\n3        plymouth satellite\n4             amc rebel sst\n\nAuto=na.omit(Auto)\ndim(Auto)\n\n[1] 392   9\n\nnames(Auto)\n\n[1] \"mpg\"          \"cylinders\"    \"displacement\" \"horsepower\"   \"weight\"      \n[6] \"acceleration\" \"year\"         \"origin\"       \"name\"        \n\n\n\n\n\n\nAuto=read.table(\"https://www.statlearning.com/s/Auto.data\",header=T,na.strings=\"?\")\ndim(Auto)\n\n[1] 397   9\n\n\n\n\n\n\n# plot(cylinders, mpg)\nplot(Auto$cylinders, Auto$mpg)\n\n\n\n\n\n\n\nattach(Auto)\nplot(cylinders, mpg)\n\n\n\n\n\n\n\ncylinders=as.factor(cylinders)\nplot(cylinders, mpg)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\")\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T,horizontal=T)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T, xlab=\"cylinders\", ylab=\"MPG\")\n\n\n\n\n\n\n\nhist(mpg)\n\n\n\n\n\n\n\nhist(mpg,col=2)\n\n\n\n\n\n\n\nhist(mpg,col=2,breaks=15)\n\n\n\n\n\n\n\n#pairs(Auto)\npairs(~ mpg + displacement + horsepower + weight + acceleration, Auto)\n\n\n\n\n\n\n\nplot(horsepower,mpg)\n\n\n\n\n\n\n\n# identify(horsepower,mpg,name) # Interactive: point and click the dot to identify cases\nsummary(Auto)\n\n      mpg          cylinders      displacement     horsepower        weight    \n Min.   : 9.00   Min.   :3.000   Min.   : 68.0   Min.   : 46.0   Min.   :1613  \n 1st Qu.:17.50   1st Qu.:4.000   1st Qu.:104.0   1st Qu.: 75.0   1st Qu.:2223  \n Median :23.00   Median :4.000   Median :146.0   Median : 93.5   Median :2800  \n Mean   :23.52   Mean   :5.458   Mean   :193.5   Mean   :104.5   Mean   :2970  \n 3rd Qu.:29.00   3rd Qu.:8.000   3rd Qu.:262.0   3rd Qu.:126.0   3rd Qu.:3609  \n Max.   :46.60   Max.   :8.000   Max.   :455.0   Max.   :230.0   Max.   :5140  \n                                                 NA's   :5                     \n  acceleration        year           origin          name          \n Min.   : 8.00   Min.   :70.00   Min.   :1.000   Length:397        \n 1st Qu.:13.80   1st Qu.:73.00   1st Qu.:1.000   Class :character  \n Median :15.50   Median :76.00   Median :1.000   Mode  :character  \n Mean   :15.56   Mean   :75.99   Mean   :1.574                     \n 3rd Qu.:17.10   3rd Qu.:79.00   3rd Qu.:2.000                     \n Max.   :24.80   Max.   :82.00   Max.   :3.000                     \n                                                                   \n\nsummary(mpg)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.00   17.50   23.00   23.52   29.00   46.60 \n\n\n\n\n\n\nptbu=c(\"MASS\",\"ISLR\")\ninstall.packages(ptbu, repos='http://cran.us.r-project.org')\n\nInstalling packages into '/Users/jimpan/Library/R/arm64/4.3/library'\n(as 'lib' is unspecified)\n\n\nWarning: package 'MASS' is not available for this version of R\n\nA version of this package for your version of R might be available elsewhere,\nsee the ideas at\nhttps://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages\n\n\n\nThe downloaded binary packages are in\n    /var/folders/m3/k788kw6103zdvc0bwpc1lzd00000gn/T//Rtmp5JyX8r/downloaded_packages\n\nlapply(ptbu, require, character.only = TRUE)\n\nLoading required package: MASS\n\n\nLoading required package: ISLR\n\n\n\nAttaching package: 'ISLR'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    Auto\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\nlibrary(MASS)\nlibrary(ISLR)\n\n# Simple Linear Regression\n\n# fix(Boston)\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\n# lm.fit=lm(medv~lstat)\nattach(Boston)\nlm.fit=lm(medv~lstat,data=Boston)\nattach(Boston)\n\nThe following objects are masked from Boston (pos = 3):\n\n    age, black, chas, crim, dis, indus, lstat, medv, nox, ptratio, rad,\n    rm, tax, zn\n\nlm.fit=lm(medv~lstat)\nlm.fit\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nCoefficients:\n(Intercept)        lstat  \n      34.55        -0.95  \n\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.168  -3.990  -1.318   2.034  24.500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 34.55384    0.56263   61.41   &lt;2e-16 ***\nlstat       -0.95005    0.03873  -24.53   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.216 on 504 degrees of freedom\nMultiple R-squared:  0.5441,    Adjusted R-squared:  0.5432 \nF-statistic: 601.6 on 1 and 504 DF,  p-value: &lt; 2.2e-16\n\nnames(lm.fit)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\ncoef(lm.fit)\n\n(Intercept)       lstat \n 34.5538409  -0.9500494 \n\nconfint(lm.fit)\n\n                2.5 %     97.5 %\n(Intercept) 33.448457 35.6592247\nlstat       -1.026148 -0.8739505\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"confidence\")\n\n       fit      lwr      upr\n1 29.80359 29.00741 30.59978\n2 25.05335 24.47413 25.63256\n3 20.30310 19.73159 20.87461\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"prediction\")\n\n       fit       lwr      upr\n1 29.80359 17.565675 42.04151\n2 25.05335 12.827626 37.27907\n3 20.30310  8.077742 32.52846\n\n# What is the differnce between \"conference\" and \"prediction\" difference?\n\nplot(lstat,medv)\nabline(lm.fit)\nabline(lm.fit,lwd=3)\nabline(lm.fit,lwd=3,col=\"red\")\n\n\n\n\n\n\n\nplot(lstat,medv,col=\"red\")\n\n\n\n\n\n\n\nplot(lstat,medv,pch=16)\n\n\n\n\n\n\n\nplot(lstat,medv,pch=\"+\")\n\n\n\n\n\n\n\nplot(1:20,1:20,pch=1:20)\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(lm.fit)\n\n\n\n\n\n\n\nplot(predict(lm.fit), residuals(lm.fit))\nplot(predict(lm.fit), rstudent(lm.fit))\nplot(hatvalues(lm.fit))\nwhich.max(hatvalues(lm.fit))\n\n375 \n375 \n\n\n\n\n\n\n\n\n\n\n\n\n\nlm.fit=lm(medv~lstat+age,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat + age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.981  -3.978  -1.283   1.968  23.158 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 33.22276    0.73085  45.458  &lt; 2e-16 ***\nlstat       -1.03207    0.04819 -21.416  &lt; 2e-16 ***\nage          0.03454    0.01223   2.826  0.00491 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.173 on 503 degrees of freedom\nMultiple R-squared:  0.5513,    Adjusted R-squared:  0.5495 \nF-statistic:   309 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nlm.fit=lm(medv~.,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ ., data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.595  -2.730  -0.518   1.777  26.199 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\ncrim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \nzn           4.642e-02  1.373e-02   3.382 0.000778 ***\nindus        2.056e-02  6.150e-02   0.334 0.738288    \nchas         2.687e+00  8.616e-01   3.118 0.001925 ** \nnox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\nrm           3.810e+00  4.179e-01   9.116  &lt; 2e-16 ***\nage          6.922e-04  1.321e-02   0.052 0.958229    \ndis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\nrad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\ntax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \nptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\nblack        9.312e-03  2.686e-03   3.467 0.000573 ***\nlstat       -5.248e-01  5.072e-02 -10.347  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.745 on 492 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 \nF-statistic: 108.1 on 13 and 492 DF,  p-value: &lt; 2.2e-16\n\nlibrary(car)\n\nLoading required package: carData\n\nvif(lm.fit)\n\n    crim       zn    indus     chas      nox       rm      age      dis \n1.792192 2.298758 3.991596 1.073995 4.393720 1.933744 3.100826 3.955945 \n     rad      tax  ptratio    black    lstat \n7.484496 9.008554 1.799084 1.348521 2.941491 \n\nlm.fit1=lm(medv~.-age,data=Boston)\nsummary(lm.fit1)\n\n\nCall:\nlm(formula = medv ~ . - age, data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.6054  -2.7313  -0.5188   1.7601  26.2243 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  36.436927   5.080119   7.172 2.72e-12 ***\ncrim         -0.108006   0.032832  -3.290 0.001075 ** \nzn            0.046334   0.013613   3.404 0.000719 ***\nindus         0.020562   0.061433   0.335 0.737989    \nchas          2.689026   0.859598   3.128 0.001863 ** \nnox         -17.713540   3.679308  -4.814 1.97e-06 ***\nrm            3.814394   0.408480   9.338  &lt; 2e-16 ***\ndis          -1.478612   0.190611  -7.757 5.03e-14 ***\nrad           0.305786   0.066089   4.627 4.75e-06 ***\ntax          -0.012329   0.003755  -3.283 0.001099 ** \nptratio      -0.952211   0.130294  -7.308 1.10e-12 ***\nblack         0.009321   0.002678   3.481 0.000544 ***\nlstat        -0.523852   0.047625 -10.999  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.74 on 493 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7343 \nF-statistic: 117.3 on 12 and 493 DF,  p-value: &lt; 2.2e-16\n\nlm.fit1=update(lm.fit, ~.-age)\n\n\n\n\n\nlm.fit2=lm(medv~lstat+I(lstat^2))\nsummary(lm.fit2)\n\n\nCall:\nlm(formula = medv ~ lstat + I(lstat^2))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.2834  -3.8313  -0.5295   2.3095  25.4148 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 42.862007   0.872084   49.15   &lt;2e-16 ***\nlstat       -2.332821   0.123803  -18.84   &lt;2e-16 ***\nI(lstat^2)   0.043547   0.003745   11.63   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.524 on 503 degrees of freedom\nMultiple R-squared:  0.6407,    Adjusted R-squared:  0.6393 \nF-statistic: 448.5 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nlm.fit=lm(medv~lstat)\nanova(lm.fit,lm.fit2)\n\nAnalysis of Variance Table\n\nModel 1: medv ~ lstat\nModel 2: medv ~ lstat + I(lstat^2)\n  Res.Df   RSS Df Sum of Sq     F    Pr(&gt;F)    \n1    504 19472                                 \n2    503 15347  1    4125.1 135.2 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npar(mfrow=c(2,2))\nplot(lm.fit2)\n\n\n\n\n\n\n\nlm.fit5=lm(medv~poly(lstat,5))\nsummary(lm.fit5)\n\n\nCall:\nlm(formula = medv ~ poly(lstat, 5))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.5433  -3.1039  -0.7052   2.0844  27.1153 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       22.5328     0.2318  97.197  &lt; 2e-16 ***\npoly(lstat, 5)1 -152.4595     5.2148 -29.236  &lt; 2e-16 ***\npoly(lstat, 5)2   64.2272     5.2148  12.316  &lt; 2e-16 ***\npoly(lstat, 5)3  -27.0511     5.2148  -5.187 3.10e-07 ***\npoly(lstat, 5)4   25.4517     5.2148   4.881 1.42e-06 ***\npoly(lstat, 5)5  -19.2524     5.2148  -3.692 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.215 on 500 degrees of freedom\nMultiple R-squared:  0.6817,    Adjusted R-squared:  0.6785 \nF-statistic: 214.2 on 5 and 500 DF,  p-value: &lt; 2.2e-16\n\nsummary(lm(medv~log(rm),data=Boston))\n\n\nCall:\nlm(formula = medv ~ log(rm), data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.487  -2.875  -0.104   2.837  39.816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -76.488      5.028  -15.21   &lt;2e-16 ***\nlog(rm)       54.055      2.739   19.73   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.915 on 504 degrees of freedom\nMultiple R-squared:  0.4358,    Adjusted R-squared:  0.4347 \nF-statistic: 389.3 on 1 and 504 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n# fix(Carseats)\nnames(Carseats)\n\n [1] \"Sales\"       \"CompPrice\"   \"Income\"      \"Advertising\" \"Population\" \n [6] \"Price\"       \"ShelveLoc\"   \"Age\"         \"Education\"   \"Urban\"      \n[11] \"US\"         \n\nlm.fit=lm(Sales~.+Income:Advertising+Price:Age,data=Carseats)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = Sales ~ . + Income:Advertising + Price:Age, data = Carseats)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9208 -0.7503  0.0177  0.6754  3.3413 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         6.5755654  1.0087470   6.519 2.22e-10 ***\nCompPrice           0.0929371  0.0041183  22.567  &lt; 2e-16 ***\nIncome              0.0108940  0.0026044   4.183 3.57e-05 ***\nAdvertising         0.0702462  0.0226091   3.107 0.002030 ** \nPopulation          0.0001592  0.0003679   0.433 0.665330    \nPrice              -0.1008064  0.0074399 -13.549  &lt; 2e-16 ***\nShelveLocGood       4.8486762  0.1528378  31.724  &lt; 2e-16 ***\nShelveLocMedium     1.9532620  0.1257682  15.531  &lt; 2e-16 ***\nAge                -0.0579466  0.0159506  -3.633 0.000318 ***\nEducation          -0.0208525  0.0196131  -1.063 0.288361    \nUrbanYes            0.1401597  0.1124019   1.247 0.213171    \nUSYes              -0.1575571  0.1489234  -1.058 0.290729    \nIncome:Advertising  0.0007510  0.0002784   2.698 0.007290 ** \nPrice:Age           0.0001068  0.0001333   0.801 0.423812    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.011 on 386 degrees of freedom\nMultiple R-squared:  0.8761,    Adjusted R-squared:  0.8719 \nF-statistic:   210 on 13 and 386 DF,  p-value: &lt; 2.2e-16\n\nattach(Carseats)\ncontrasts(ShelveLoc)\n\n       Good Medium\nBad       0      0\nGood      1      0\nMedium    0      1\n\n\n\n\n\n\nsummary(lm(medv~lstat*age,data=Boston))\n\n\nCall:\nlm(formula = medv ~ lstat * age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.806  -4.045  -1.333   2.085  27.552 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 36.0885359  1.4698355  24.553  &lt; 2e-16 ***\nlstat       -1.3921168  0.1674555  -8.313 8.78e-16 ***\nage         -0.0007209  0.0198792  -0.036   0.9711    \nlstat:age    0.0041560  0.0018518   2.244   0.0252 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.149 on 502 degrees of freedom\nMultiple R-squared:  0.5557,    Adjusted R-squared:  0.5531 \nF-statistic: 209.3 on 3 and 502 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "EPPS 6323: Lab02"
    ]
  },
  {
    "objectID": "Lab02.html#indexing-data-using",
    "href": "Lab02.html#indexing-data-using",
    "title": "EPPS 6323: Lab02",
    "section": "",
    "text": "A=matrix(1:16,4,4)\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\nA[2,3]\n\n[1] 10\n\nA[c(1,3),c(2,4)]\n\n     [,1] [,2]\n[1,]    5   13\n[2,]    7   15\n\nA[1:3,2:4]\n\n     [,1] [,2] [,3]\n[1,]    5    9   13\n[2,]    6   10   14\n[3,]    7   11   15\n\nA[1:2,]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n\nA[,1:2]\n\n     [,1] [,2]\n[1,]    1    5\n[2,]    2    6\n[3,]    3    7\n[4,]    4    8\n\nA[1,]\n\n[1]  1  5  9 13\n\nA[-c(1,3),]\n\n     [,1] [,2] [,3] [,4]\n[1,]    2    6   10   14\n[2,]    4    8   12   16\n\nA[-c(1,3),-c(1,3,4)]\n\n[1] 6 8\n\ndim(A)\n\n[1] 4 4",
    "crumbs": [
      "EPPS 6323: Lab02"
    ]
  },
  {
    "objectID": "Lab02.html#loading-data-from-github",
    "href": "Lab02.html#loading-data-from-github",
    "title": "EPPS 6323: Lab02",
    "section": "",
    "text": "Auto=read.table(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.data\")\n# fix(Auto) # Starting the X11 R data editor\nAuto=read.table(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.data\",header=T,na.strings=\"?\")\n# fix(Auto)\nAuto=read.csv(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.csv\",header=T,na.strings=\"?\")\n# fix(Auto)\ndim(Auto)\n\n[1] 397   9\n\nAuto[1:4,]\n\n  mpg cylinders displacement horsepower weight acceleration year origin\n1  18         8          307        130   3504         12.0   70      1\n2  15         8          350        165   3693         11.5   70      1\n3  18         8          318        150   3436         11.0   70      1\n4  16         8          304        150   3433         12.0   70      1\n                       name\n1 chevrolet chevelle malibu\n2         buick skylark 320\n3        plymouth satellite\n4             amc rebel sst\n\nAuto=na.omit(Auto)\ndim(Auto)\n\n[1] 392   9\n\nnames(Auto)\n\n[1] \"mpg\"          \"cylinders\"    \"displacement\" \"horsepower\"   \"weight\"      \n[6] \"acceleration\" \"year\"         \"origin\"       \"name\"",
    "crumbs": [
      "EPPS 6323: Lab02"
    ]
  },
  {
    "objectID": "Lab02.html#load-data-from-islr-website",
    "href": "Lab02.html#load-data-from-islr-website",
    "title": "EPPS 6323: Lab02",
    "section": "",
    "text": "Auto=read.table(\"https://www.statlearning.com/s/Auto.data\",header=T,na.strings=\"?\")\ndim(Auto)\n\n[1] 397   9",
    "crumbs": [
      "EPPS 6323: Lab02"
    ]
  },
  {
    "objectID": "Lab02.html#additional-graphical-and-numerical-summaries",
    "href": "Lab02.html#additional-graphical-and-numerical-summaries",
    "title": "EPPS 6323: Lab02",
    "section": "",
    "text": "# plot(cylinders, mpg)\nplot(Auto$cylinders, Auto$mpg)\n\n\n\n\n\n\n\nattach(Auto)\nplot(cylinders, mpg)\n\n\n\n\n\n\n\ncylinders=as.factor(cylinders)\nplot(cylinders, mpg)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\")\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T,horizontal=T)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T, xlab=\"cylinders\", ylab=\"MPG\")\n\n\n\n\n\n\n\nhist(mpg)\n\n\n\n\n\n\n\nhist(mpg,col=2)\n\n\n\n\n\n\n\nhist(mpg,col=2,breaks=15)\n\n\n\n\n\n\n\n#pairs(Auto)\npairs(~ mpg + displacement + horsepower + weight + acceleration, Auto)\n\n\n\n\n\n\n\nplot(horsepower,mpg)\n\n\n\n\n\n\n\n# identify(horsepower,mpg,name) # Interactive: point and click the dot to identify cases\nsummary(Auto)\n\n      mpg          cylinders      displacement     horsepower        weight    \n Min.   : 9.00   Min.   :3.000   Min.   : 68.0   Min.   : 46.0   Min.   :1613  \n 1st Qu.:17.50   1st Qu.:4.000   1st Qu.:104.0   1st Qu.: 75.0   1st Qu.:2223  \n Median :23.00   Median :4.000   Median :146.0   Median : 93.5   Median :2800  \n Mean   :23.52   Mean   :5.458   Mean   :193.5   Mean   :104.5   Mean   :2970  \n 3rd Qu.:29.00   3rd Qu.:8.000   3rd Qu.:262.0   3rd Qu.:126.0   3rd Qu.:3609  \n Max.   :46.60   Max.   :8.000   Max.   :455.0   Max.   :230.0   Max.   :5140  \n                                                 NA's   :5                     \n  acceleration        year           origin          name          \n Min.   : 8.00   Min.   :70.00   Min.   :1.000   Length:397        \n 1st Qu.:13.80   1st Qu.:73.00   1st Qu.:1.000   Class :character  \n Median :15.50   Median :76.00   Median :1.000   Mode  :character  \n Mean   :15.56   Mean   :75.99   Mean   :1.574                     \n 3rd Qu.:17.10   3rd Qu.:79.00   3rd Qu.:2.000                     \n Max.   :24.80   Max.   :82.00   Max.   :3.000                     \n                                                                   \n\nsummary(mpg)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.00   17.50   23.00   23.52   29.00   46.60",
    "crumbs": [
      "EPPS 6323: Lab02"
    ]
  },
  {
    "objectID": "Lab02.html#linear-regression",
    "href": "Lab02.html#linear-regression",
    "title": "EPPS 6323: Lab02",
    "section": "",
    "text": "ptbu=c(\"MASS\",\"ISLR\")\ninstall.packages(ptbu, repos='http://cran.us.r-project.org')\n\nInstalling packages into '/Users/jimpan/Library/R/arm64/4.3/library'\n(as 'lib' is unspecified)\n\n\nWarning: package 'MASS' is not available for this version of R\n\nA version of this package for your version of R might be available elsewhere,\nsee the ideas at\nhttps://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages\n\n\n\nThe downloaded binary packages are in\n    /var/folders/m3/k788kw6103zdvc0bwpc1lzd00000gn/T//Rtmp5JyX8r/downloaded_packages\n\nlapply(ptbu, require, character.only = TRUE)\n\nLoading required package: MASS\n\n\nLoading required package: ISLR\n\n\n\nAttaching package: 'ISLR'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    Auto\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\nlibrary(MASS)\nlibrary(ISLR)\n\n# Simple Linear Regression\n\n# fix(Boston)\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\n# lm.fit=lm(medv~lstat)\nattach(Boston)\nlm.fit=lm(medv~lstat,data=Boston)\nattach(Boston)\n\nThe following objects are masked from Boston (pos = 3):\n\n    age, black, chas, crim, dis, indus, lstat, medv, nox, ptratio, rad,\n    rm, tax, zn\n\nlm.fit=lm(medv~lstat)\nlm.fit\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nCoefficients:\n(Intercept)        lstat  \n      34.55        -0.95  \n\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.168  -3.990  -1.318   2.034  24.500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 34.55384    0.56263   61.41   &lt;2e-16 ***\nlstat       -0.95005    0.03873  -24.53   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.216 on 504 degrees of freedom\nMultiple R-squared:  0.5441,    Adjusted R-squared:  0.5432 \nF-statistic: 601.6 on 1 and 504 DF,  p-value: &lt; 2.2e-16\n\nnames(lm.fit)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\ncoef(lm.fit)\n\n(Intercept)       lstat \n 34.5538409  -0.9500494 \n\nconfint(lm.fit)\n\n                2.5 %     97.5 %\n(Intercept) 33.448457 35.6592247\nlstat       -1.026148 -0.8739505\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"confidence\")\n\n       fit      lwr      upr\n1 29.80359 29.00741 30.59978\n2 25.05335 24.47413 25.63256\n3 20.30310 19.73159 20.87461\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"prediction\")\n\n       fit       lwr      upr\n1 29.80359 17.565675 42.04151\n2 25.05335 12.827626 37.27907\n3 20.30310  8.077742 32.52846\n\n# What is the differnce between \"conference\" and \"prediction\" difference?\n\nplot(lstat,medv)\nabline(lm.fit)\nabline(lm.fit,lwd=3)\nabline(lm.fit,lwd=3,col=\"red\")\n\n\n\n\n\n\n\nplot(lstat,medv,col=\"red\")\n\n\n\n\n\n\n\nplot(lstat,medv,pch=16)\n\n\n\n\n\n\n\nplot(lstat,medv,pch=\"+\")\n\n\n\n\n\n\n\nplot(1:20,1:20,pch=1:20)\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(lm.fit)\n\n\n\n\n\n\n\nplot(predict(lm.fit), residuals(lm.fit))\nplot(predict(lm.fit), rstudent(lm.fit))\nplot(hatvalues(lm.fit))\nwhich.max(hatvalues(lm.fit))\n\n375 \n375",
    "crumbs": [
      "EPPS 6323: Lab02"
    ]
  },
  {
    "objectID": "Lab02.html#multiple-linear-regression",
    "href": "Lab02.html#multiple-linear-regression",
    "title": "EPPS 6323: Lab02",
    "section": "",
    "text": "lm.fit=lm(medv~lstat+age,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat + age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.981  -3.978  -1.283   1.968  23.158 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 33.22276    0.73085  45.458  &lt; 2e-16 ***\nlstat       -1.03207    0.04819 -21.416  &lt; 2e-16 ***\nage          0.03454    0.01223   2.826  0.00491 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.173 on 503 degrees of freedom\nMultiple R-squared:  0.5513,    Adjusted R-squared:  0.5495 \nF-statistic:   309 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nlm.fit=lm(medv~.,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ ., data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.595  -2.730  -0.518   1.777  26.199 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\ncrim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \nzn           4.642e-02  1.373e-02   3.382 0.000778 ***\nindus        2.056e-02  6.150e-02   0.334 0.738288    \nchas         2.687e+00  8.616e-01   3.118 0.001925 ** \nnox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\nrm           3.810e+00  4.179e-01   9.116  &lt; 2e-16 ***\nage          6.922e-04  1.321e-02   0.052 0.958229    \ndis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\nrad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\ntax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \nptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\nblack        9.312e-03  2.686e-03   3.467 0.000573 ***\nlstat       -5.248e-01  5.072e-02 -10.347  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.745 on 492 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 \nF-statistic: 108.1 on 13 and 492 DF,  p-value: &lt; 2.2e-16\n\nlibrary(car)\n\nLoading required package: carData\n\nvif(lm.fit)\n\n    crim       zn    indus     chas      nox       rm      age      dis \n1.792192 2.298758 3.991596 1.073995 4.393720 1.933744 3.100826 3.955945 \n     rad      tax  ptratio    black    lstat \n7.484496 9.008554 1.799084 1.348521 2.941491 \n\nlm.fit1=lm(medv~.-age,data=Boston)\nsummary(lm.fit1)\n\n\nCall:\nlm(formula = medv ~ . - age, data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.6054  -2.7313  -0.5188   1.7601  26.2243 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  36.436927   5.080119   7.172 2.72e-12 ***\ncrim         -0.108006   0.032832  -3.290 0.001075 ** \nzn            0.046334   0.013613   3.404 0.000719 ***\nindus         0.020562   0.061433   0.335 0.737989    \nchas          2.689026   0.859598   3.128 0.001863 ** \nnox         -17.713540   3.679308  -4.814 1.97e-06 ***\nrm            3.814394   0.408480   9.338  &lt; 2e-16 ***\ndis          -1.478612   0.190611  -7.757 5.03e-14 ***\nrad           0.305786   0.066089   4.627 4.75e-06 ***\ntax          -0.012329   0.003755  -3.283 0.001099 ** \nptratio      -0.952211   0.130294  -7.308 1.10e-12 ***\nblack         0.009321   0.002678   3.481 0.000544 ***\nlstat        -0.523852   0.047625 -10.999  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.74 on 493 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7343 \nF-statistic: 117.3 on 12 and 493 DF,  p-value: &lt; 2.2e-16\n\nlm.fit1=update(lm.fit, ~.-age)",
    "crumbs": [
      "EPPS 6323: Lab02"
    ]
  },
  {
    "objectID": "Lab02.html#non-linear-transformations-of-the-predictors",
    "href": "Lab02.html#non-linear-transformations-of-the-predictors",
    "title": "EPPS 6323: Lab02",
    "section": "",
    "text": "lm.fit2=lm(medv~lstat+I(lstat^2))\nsummary(lm.fit2)\n\n\nCall:\nlm(formula = medv ~ lstat + I(lstat^2))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.2834  -3.8313  -0.5295   2.3095  25.4148 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 42.862007   0.872084   49.15   &lt;2e-16 ***\nlstat       -2.332821   0.123803  -18.84   &lt;2e-16 ***\nI(lstat^2)   0.043547   0.003745   11.63   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.524 on 503 degrees of freedom\nMultiple R-squared:  0.6407,    Adjusted R-squared:  0.6393 \nF-statistic: 448.5 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nlm.fit=lm(medv~lstat)\nanova(lm.fit,lm.fit2)\n\nAnalysis of Variance Table\n\nModel 1: medv ~ lstat\nModel 2: medv ~ lstat + I(lstat^2)\n  Res.Df   RSS Df Sum of Sq     F    Pr(&gt;F)    \n1    504 19472                                 \n2    503 15347  1    4125.1 135.2 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npar(mfrow=c(2,2))\nplot(lm.fit2)\n\n\n\n\n\n\n\nlm.fit5=lm(medv~poly(lstat,5))\nsummary(lm.fit5)\n\n\nCall:\nlm(formula = medv ~ poly(lstat, 5))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.5433  -3.1039  -0.7052   2.0844  27.1153 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       22.5328     0.2318  97.197  &lt; 2e-16 ***\npoly(lstat, 5)1 -152.4595     5.2148 -29.236  &lt; 2e-16 ***\npoly(lstat, 5)2   64.2272     5.2148  12.316  &lt; 2e-16 ***\npoly(lstat, 5)3  -27.0511     5.2148  -5.187 3.10e-07 ***\npoly(lstat, 5)4   25.4517     5.2148   4.881 1.42e-06 ***\npoly(lstat, 5)5  -19.2524     5.2148  -3.692 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.215 on 500 degrees of freedom\nMultiple R-squared:  0.6817,    Adjusted R-squared:  0.6785 \nF-statistic: 214.2 on 5 and 500 DF,  p-value: &lt; 2.2e-16\n\nsummary(lm(medv~log(rm),data=Boston))\n\n\nCall:\nlm(formula = medv ~ log(rm), data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.487  -2.875  -0.104   2.837  39.816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -76.488      5.028  -15.21   &lt;2e-16 ***\nlog(rm)       54.055      2.739   19.73   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.915 on 504 degrees of freedom\nMultiple R-squared:  0.4358,    Adjusted R-squared:  0.4347 \nF-statistic: 389.3 on 1 and 504 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "EPPS 6323: Lab02"
    ]
  },
  {
    "objectID": "Lab02.html#qualitative-predictors",
    "href": "Lab02.html#qualitative-predictors",
    "title": "EPPS 6323: Lab02",
    "section": "",
    "text": "# fix(Carseats)\nnames(Carseats)\n\n [1] \"Sales\"       \"CompPrice\"   \"Income\"      \"Advertising\" \"Population\" \n [6] \"Price\"       \"ShelveLoc\"   \"Age\"         \"Education\"   \"Urban\"      \n[11] \"US\"         \n\nlm.fit=lm(Sales~.+Income:Advertising+Price:Age,data=Carseats)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = Sales ~ . + Income:Advertising + Price:Age, data = Carseats)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9208 -0.7503  0.0177  0.6754  3.3413 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         6.5755654  1.0087470   6.519 2.22e-10 ***\nCompPrice           0.0929371  0.0041183  22.567  &lt; 2e-16 ***\nIncome              0.0108940  0.0026044   4.183 3.57e-05 ***\nAdvertising         0.0702462  0.0226091   3.107 0.002030 ** \nPopulation          0.0001592  0.0003679   0.433 0.665330    \nPrice              -0.1008064  0.0074399 -13.549  &lt; 2e-16 ***\nShelveLocGood       4.8486762  0.1528378  31.724  &lt; 2e-16 ***\nShelveLocMedium     1.9532620  0.1257682  15.531  &lt; 2e-16 ***\nAge                -0.0579466  0.0159506  -3.633 0.000318 ***\nEducation          -0.0208525  0.0196131  -1.063 0.288361    \nUrbanYes            0.1401597  0.1124019   1.247 0.213171    \nUSYes              -0.1575571  0.1489234  -1.058 0.290729    \nIncome:Advertising  0.0007510  0.0002784   2.698 0.007290 ** \nPrice:Age           0.0001068  0.0001333   0.801 0.423812    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.011 on 386 degrees of freedom\nMultiple R-squared:  0.8761,    Adjusted R-squared:  0.8719 \nF-statistic:   210 on 13 and 386 DF,  p-value: &lt; 2.2e-16\n\nattach(Carseats)\ncontrasts(ShelveLoc)\n\n       Good Medium\nBad       0      0\nGood      1      0\nMedium    0      1",
    "crumbs": [
      "EPPS 6323: Lab02"
    ]
  },
  {
    "objectID": "Lab02.html#interaction-terms-including-interaction-and-single-effects",
    "href": "Lab02.html#interaction-terms-including-interaction-and-single-effects",
    "title": "EPPS 6323: Lab02",
    "section": "",
    "text": "summary(lm(medv~lstat*age,data=Boston))\n\n\nCall:\nlm(formula = medv ~ lstat * age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.806  -4.045  -1.333   2.085  27.552 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 36.0885359  1.4698355  24.553  &lt; 2e-16 ***\nlstat       -1.3921168  0.1674555  -8.313 8.78e-16 ***\nage         -0.0007209  0.0198792  -0.036   0.9711    \nlstat:age    0.0041560  0.0018518   2.244   0.0252 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.149 on 502 degrees of freedom\nMultiple R-squared:  0.5557,    Adjusted R-squared:  0.5531 \nF-statistic: 209.3 on 3 and 502 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "EPPS 6323: Lab02"
    ]
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Jimpan's Knowledge Hub",
    "section": "",
    "text": "You have come to the wasteland of knowledge, which will be updated soon.\n\n\n\n Back to top"
  },
  {
    "objectID": "comfyui.html",
    "href": "comfyui.html",
    "title": "ComfyUI",
    "section": "",
    "text": "ComfyUI is a modular, node-based interface for AI-powered image and animation generation. It allows users to have granular control over each step of the creative process, from model selection to image output. ComfyUI is designed to provide both flexibility and precision, making it a great tool for both beginners and advanced users.\n\n\n\n\n\nWorkflow Sample\n\n\n\n\n\n\n\n\nWorkflow Sample2\n\n\n\n\n\n\nNode-based Workflow: ComfyUI’s interface is built around connecting nodes, each representing a different function or action in the image generation process. This allows for customized workflows to suit specific project requirements.\nAI Model Support: ComfyUI integrates with popular AI models, including Stable Diffusion and ControlNet, offering a broad range of image generation capabilities like text-to-image, image-to-image, and more.\nAdvanced Control: Users can modify and control various parameters such as sampling methods, resolutions, and image styles, providing detailed customization for output refinement.\n\n\n\n\n\nCreative Flexibility: ComfyUI’s open-ended design encourages experimentation, letting users craft complex workflows tailored to their specific creative needs.\nDetailed Customization: Adjust key aspects of the workflow to fine-tune the results, including models, prompts, and even the post-processing stages.\nIntegration with Other AI Tools: Seamless integration with models like ControlNet enables precise control over elements like poses, faces, and more within generated images.\n\n\n\n\n\nText-to-Image: Input a prompt and generate images using models like Stable Diffusion. Modify the process using various nodes to get the exact style or detail you need.\nImage Modification: Generate variations of existing images by using nodes that apply transformations or post-processing filters to enhance or change the image.\nAnimation Creation: By linking multiple image outputs and nodes, ComfyUI can be used to create dynamic animations with controlled transitions between frames.\n\n\n\n\nFor more information, updates, or to contribute to the project, you can visit the official ComfyUI GitHub Repository.",
    "crumbs": [
      "AI Art & Animation",
      "ComfyUI"
    ]
  },
  {
    "objectID": "comfyui.html#key-features",
    "href": "comfyui.html#key-features",
    "title": "ComfyUI",
    "section": "",
    "text": "Node-based Workflow: ComfyUI’s interface is built around connecting nodes, each representing a different function or action in the image generation process. This allows for customized workflows to suit specific project requirements.\nAI Model Support: ComfyUI integrates with popular AI models, including Stable Diffusion and ControlNet, offering a broad range of image generation capabilities like text-to-image, image-to-image, and more.\nAdvanced Control: Users can modify and control various parameters such as sampling methods, resolutions, and image styles, providing detailed customization for output refinement.",
    "crumbs": [
      "AI Art & Animation",
      "ComfyUI"
    ]
  },
  {
    "objectID": "comfyui.html#why-use-comfyui",
    "href": "comfyui.html#why-use-comfyui",
    "title": "ComfyUI",
    "section": "",
    "text": "Creative Flexibility: ComfyUI’s open-ended design encourages experimentation, letting users craft complex workflows tailored to their specific creative needs.\nDetailed Customization: Adjust key aspects of the workflow to fine-tune the results, including models, prompts, and even the post-processing stages.\nIntegration with Other AI Tools: Seamless integration with models like ControlNet enables precise control over elements like poses, faces, and more within generated images.",
    "crumbs": [
      "AI Art & Animation",
      "ComfyUI"
    ]
  },
  {
    "objectID": "comfyui.html#how-it-works",
    "href": "comfyui.html#how-it-works",
    "title": "ComfyUI",
    "section": "",
    "text": "Text-to-Image: Input a prompt and generate images using models like Stable Diffusion. Modify the process using various nodes to get the exact style or detail you need.\nImage Modification: Generate variations of existing images by using nodes that apply transformations or post-processing filters to enhance or change the image.\nAnimation Creation: By linking multiple image outputs and nodes, ComfyUI can be used to create dynamic animations with controlled transitions between frames.",
    "crumbs": [
      "AI Art & Animation",
      "ComfyUI"
    ]
  },
  {
    "objectID": "comfyui.html#official-github-repository",
    "href": "comfyui.html#official-github-repository",
    "title": "ComfyUI",
    "section": "",
    "text": "For more information, updates, or to contribute to the project, you can visit the official ComfyUI GitHub Repository.",
    "crumbs": [
      "AI Art & Animation",
      "ComfyUI"
    ]
  },
  {
    "objectID": "6381Lab08.html",
    "href": "6381Lab08.html",
    "title": "Lab 08: Spatial Analysis Buffering and Overlay",
    "section": "",
    "text": "In this lab, we will explore spatial analysis techniques using buffering and overlay operations in ArcGIS. These techniques are fundamental in geographic information systems (GIS) and are often used to determine spatial relationships between various features.",
    "crumbs": [
      "ArcGIS",
      "Lab 08: Spatial Analysis Buffering and Overlay"
    ]
  },
  {
    "objectID": "6381Lab08.html#introduction",
    "href": "6381Lab08.html#introduction",
    "title": "Lab 08: Spatial Analysis Buffering and Overlay",
    "section": "",
    "text": "In this lab, we will explore spatial analysis techniques using buffering and overlay operations in ArcGIS. These techniques are fundamental in geographic information systems (GIS) and are often used to determine spatial relationships between various features.",
    "crumbs": [
      "ArcGIS",
      "Lab 08: Spatial Analysis Buffering and Overlay"
    ]
  },
  {
    "objectID": "6381Lab08.html#objectives",
    "href": "6381Lab08.html#objectives",
    "title": "Lab 08: Spatial Analysis Buffering and Overlay",
    "section": "2 Objectives",
    "text": "2 Objectives\n\nApply the concepts of buffering and overlay in GIS.\nCreate maps demonstrating buffer zones and suitable areas for specific land use.\nPerform spatial analysis to identify potential campgrounds based on proximity to lakes and roads.",
    "crumbs": [
      "ArcGIS",
      "Lab 08: Spatial Analysis Buffering and Overlay"
    ]
  },
  {
    "objectID": "6381Lab08.html#tasks",
    "href": "6381Lab08.html#tasks",
    "title": "Lab 08: Spatial Analysis Buffering and Overlay",
    "section": "3 Tasks",
    "text": "3 Tasks\n\n3.1 1. Create Buffer Zones\nUsing the provided data (lakes.shp, roads.shp), generate buffer zones around lakes and roads. Apply variable distance buffers for lakes based on their size and fixed distance buffers for roads.\n\n\n3.2 2. Perform Overlay Analysis\nOverlay the buffer zones to identify areas that meet both the criteria for being near a lake and a road. Use the union operation to combine these layers and identify suitable areas for potential campgrounds.\n\n\n3.3 3. Analyze Suitable Areas\nDetermine the size of the suitable areas identified in the overlay analysis. Calculate the area in hectares and create maps that display these areas.",
    "crumbs": [
      "ArcGIS",
      "Lab 08: Spatial Analysis Buffering and Overlay"
    ]
  },
  {
    "objectID": "6381Lab08.html#results",
    "href": "6381Lab08.html#results",
    "title": "Lab 08: Spatial Analysis Buffering and Overlay",
    "section": "4 Results",
    "text": "4 Results\n\n4.1 Hugo Minnesota Lakes and Roads - Buffer Zones\n\n\n\nBuffer Zones\n\n\n\n\n4.2 Hugo Minnesota Lakes and Roads - Overlay Analysis\n\n\n\nOverlay Analysis\n\n\n\n\n4.3 Hugo Minnesota Lakes and Roads - Campground Locations\n\n\n\nCampground Locations",
    "crumbs": [
      "ArcGIS",
      "Lab 08: Spatial Analysis Buffering and Overlay"
    ]
  },
  {
    "objectID": "6381Lab08.html#conclusion",
    "href": "6381Lab08.html#conclusion",
    "title": "Lab 08: Spatial Analysis Buffering and Overlay",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nThis lab demonstrated the use of buffering and overlay operations in GIS to identify suitable areas for campgrounds. By applying these spatial analysis techniques, we can make informed decisions about land use based on proximity to key features such as lakes and roads.",
    "crumbs": [
      "ArcGIS",
      "Lab 08: Spatial Analysis Buffering and Overlay"
    ]
  },
  {
    "objectID": "arcgis.html",
    "href": "arcgis.html",
    "title": "ArcGIS Labs Overview",
    "section": "",
    "text": "Please use sidebar to view labs.\nWelcome to the ArcGIS Labs section of my project. This page serves as an overview and gateway to the various labs conducted using ArcGIS, a powerful tool for geographic information system (GIS) analysis. These labs are designed to enhance my skills in spatial data analysis, cartography, and remote sensing.\n\n\n\n\n\nLayout Sample",
    "crumbs": [
      "ArcGIS",
      "ArcGIS Labs Overview"
    ]
  },
  {
    "objectID": "arcgis.html#introduction",
    "href": "arcgis.html#introduction",
    "title": "ArcGIS Labs Overview",
    "section": "",
    "text": "Please use sidebar to view labs.\nWelcome to the ArcGIS Labs section of my project. This page serves as an overview and gateway to the various labs conducted using ArcGIS, a powerful tool for geographic information system (GIS) analysis. These labs are designed to enhance my skills in spatial data analysis, cartography, and remote sensing.\n\n\n\n\n\nLayout Sample",
    "crumbs": [
      "ArcGIS",
      "ArcGIS Labs Overview"
    ]
  },
  {
    "objectID": "arcgis.html#objectives",
    "href": "arcgis.html#objectives",
    "title": "ArcGIS Labs Overview",
    "section": "2 Objectives",
    "text": "2 Objectives\nThe primary objectives of these labs are:\n\nTo gain hands-on experience with ArcGIS software.\nTo develop proficiency in various GIS analysis techniques, including spatial analysis, raster processing, and remote sensing.\nTo apply these techniques to real-world scenarios, such as land cover analysis, population studies, and environmental monitoring.",
    "crumbs": [
      "ArcGIS",
      "ArcGIS Labs Overview"
    ]
  },
  {
    "objectID": "arcgis.html#lab-summaries",
    "href": "arcgis.html#lab-summaries",
    "title": "ArcGIS Labs Overview",
    "section": "3 Lab Summaries",
    "text": "3 Lab Summaries\n\n3.1 Lab 01: Introduction to ArcGIS\nAn introductory lab focusing on getting familiar with the ArcGIS interface and basic functions. Topics include map navigation, layer management, and simple spatial queries.\n\n\n3.2 Lab 02: Projections in ArcGIS\nThis lab covers the importance of map projections and how to work with different coordinate systems in ArcGIS. You will learn to project spatial data accurately and analyze how projections impact spatial analysis.\n\n\n3.3 Lab 03: Data Entry and Editing\nThis lab teaches how to digitize spatial features, edit attributes, and manage spatial data effectively. It’s a crucial skill for maintaining accurate and up-to-date GIS datasets.\n\n\n3.4 Lab 04: Digitizing and Topology\nExplore advanced digitizing techniques and learn about the role of topology in maintaining spatial data integrity. The lab includes practical exercises in creating and correcting topological errors.\n\n\n3.5 Lab 05: Working with Digital Data and Tables\nLearn how to import, manage, and analyze tabular data within ArcGIS. This lab focuses on linking spatial data with attribute tables and performing table-based queries.\n\n\n3.6 Lab 06: Advanced Table Operations\nThis lab delves into more complex table operations, including joins, relates, and summarization techniques, which are essential for in-depth spatial analysis.\n\n\n3.7 Lab 07: Spatial Selection and Queries\nLearn to perform spatial queries and selections based on various criteria. This lab demonstrates how to extract meaningful information from large spatial datasets.\n\n\n3.8 Lab 08: Buffering and Overlay Analysis\nThis lab covers buffering and overlay techniques to analyze spatial relationships. It’s commonly used in environmental impact studies and site suitability analyses.\n\n\n3.9 Lab 09: Raster Data Analysis\nExplore raster data processing techniques, including classification, reclassification, and raster algebra. The lab emphasizes the use of raster data for land cover and elevation analysis.\n\n\n3.10 Lab 10: Remote Sensing Data\nThis lab focuses on remote sensing applications, including the use of Landsat imagery for land cover change detection and environmental monitoring.",
    "crumbs": [
      "ArcGIS",
      "ArcGIS Labs Overview"
    ]
  },
  {
    "objectID": "arcgis.html#conclusion",
    "href": "arcgis.html#conclusion",
    "title": "ArcGIS Labs Overview",
    "section": "4 Conclusion",
    "text": "4 Conclusion\nThese labs represent a comprehensive journey through the functionalities of ArcGIS, from basic operations to advanced spatial analysis techniques. Each lab builds on the previous ones, progressively expanding the range of skills and knowledge in GIS. Feel free to explore each lab in detail to see the results and methodologies used.",
    "crumbs": [
      "ArcGIS",
      "ArcGIS Labs Overview"
    ]
  },
  {
    "objectID": "arcgis.html#next-steps",
    "href": "arcgis.html#next-steps",
    "title": "ArcGIS Labs Overview",
    "section": "5 Next Steps",
    "text": "5 Next Steps\nAs I continue to learn and apply GIS techniques, I will be adding more labs and projects to this section. Stay tuned for updates!",
    "crumbs": [
      "ArcGIS",
      "ArcGIS Labs Overview"
    ]
  },
  {
    "objectID": "assign01.html",
    "href": "assign01.html",
    "title": "Jimpan's Knowledge Hub",
    "section": "",
    "text": "You have come to the wasteland of knowledge, which will be updated soon.\n\n\n\n Back to top",
    "crumbs": [
      "assign01.html"
    ]
  },
  {
    "objectID": "6381Lab03.html",
    "href": "6381Lab03.html",
    "title": "Lab 03: Data Entry and Digitizing",
    "section": "",
    "text": "This lab focuses on the processes of manual and on-screen digitizing within ArcGIS Pro. The primary goal is to digitize features from aerial imagery and other source media, creating accurate vector data layers.",
    "crumbs": [
      "ArcGIS",
      "Lab 03: Data Entry and Digitizing"
    ]
  },
  {
    "objectID": "6381Lab03.html#introduction",
    "href": "6381Lab03.html#introduction",
    "title": "Lab 03: Data Entry and Digitizing",
    "section": "",
    "text": "This lab focuses on the processes of manual and on-screen digitizing within ArcGIS Pro. The primary goal is to digitize features from aerial imagery and other source media, creating accurate vector data layers.",
    "crumbs": [
      "ArcGIS",
      "Lab 03: Data Entry and Digitizing"
    ]
  },
  {
    "objectID": "6381Lab03.html#objectives",
    "href": "6381Lab03.html#objectives",
    "title": "Lab 03: Data Entry and Digitizing",
    "section": "2 Objectives",
    "text": "2 Objectives\n\nDigitize features such as buildings, roads, and ponds using ArcGIS Pro.\nUtilize snapping tools to ensure precision in editing.\nSave and export digitized features in map formats.",
    "crumbs": [
      "ArcGIS",
      "Lab 03: Data Entry and Digitizing"
    ]
  },
  {
    "objectID": "6381Lab03.html#tasks",
    "href": "6381Lab03.html#tasks",
    "title": "Lab 03: Data Entry and Digitizing",
    "section": "3 Tasks",
    "text": "3 Tasks\n\n3.1 1. Digitize Landcover and Subdivision Polygons\nUse aerial imagery as the base layer to digitize landcover and new subdivision polygons. Apply snapping tools to ensure that all features are correctly aligned.\n\n\n3.2 2. Digitize MAP Township Features\nTrace and digitize features such as buildings, roads, and ponds in MAP Township. Ensure each feature is accurately represented in the vector data layer.",
    "crumbs": [
      "ArcGIS",
      "Lab 03: Data Entry and Digitizing"
    ]
  },
  {
    "objectID": "6381Lab03.html#results",
    "href": "6381Lab03.html#results",
    "title": "Lab 03: Data Entry and Digitizing",
    "section": "4 Results",
    "text": "4 Results\n\n4.1 Updated Landcover and Subdivision Polygons\n\n\n\nEditing Practice\n\n\n\n\n4.2 MAP Township Digitized Features\n\n\n\nMAP Township",
    "crumbs": [
      "ArcGIS",
      "Lab 03: Data Entry and Digitizing"
    ]
  },
  {
    "objectID": "6381Lab03.html#conclusion",
    "href": "6381Lab03.html#conclusion",
    "title": "Lab 03: Data Entry and Digitizing",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nDigitizing features from aerial imagery allows for the accurate creation of vector data layers, essential for many GIS applications. Proper use of snapping tools ensures that digitized features are precise, which is critical in producing reliable spatial data.",
    "crumbs": [
      "ArcGIS",
      "Lab 03: Data Entry and Digitizing"
    ]
  },
  {
    "objectID": "vid2vid.html",
    "href": "vid2vid.html",
    "title": "v2v",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "AI Art & Animation",
      "v2v"
    ]
  },
  {
    "objectID": "6381Lab01.html",
    "href": "6381Lab01.html",
    "title": "Lab 01: Introduction to ArcGIS and Basic Map Operations",
    "section": "",
    "text": "This lab introduces ArcGIS software and covers basic map operations, including working with shapefiles, creating new layers, and exporting maps.",
    "crumbs": [
      "ArcGIS",
      "Lab 01: Introduction to ArcGIS and Basic Map Operations"
    ]
  },
  {
    "objectID": "6381Lab01.html#objective",
    "href": "6381Lab01.html#objective",
    "title": "Lab 01: Introduction to ArcGIS and Basic Map Operations",
    "section": "",
    "text": "This lab introduces ArcGIS software and covers basic map operations, including working with shapefiles, creating new layers, and exporting maps.",
    "crumbs": [
      "ArcGIS",
      "Lab 01: Introduction to ArcGIS and Basic Map Operations"
    ]
  },
  {
    "objectID": "6381Lab01.html#procedure",
    "href": "6381Lab01.html#procedure",
    "title": "Lab 01: Introduction to ArcGIS and Basic Map Operations",
    "section": "2 Procedure",
    "text": "2 Procedure\n\nIntroduction to ArcGIS: Familiarized with the ArcGIS interface and explored essential tools and functions.\nWorking with Shapefiles: Imported and managed shapefiles, with a focus on understanding attribute tables and layer properties.\nCreating New Layers: Developed new layers by extracting specific features and attributes.\nExporting Maps: Exported maps in PDF format for documentation and presentation purposes.",
    "crumbs": [
      "ArcGIS",
      "Lab 01: Introduction to ArcGIS and Basic Map Operations"
    ]
  },
  {
    "objectID": "6381Lab01.html#results",
    "href": "6381Lab01.html#results",
    "title": "Lab 01: Introduction to ArcGIS and Basic Map Operations",
    "section": "3 Results",
    "text": "3 Results\nBelow are the results generated during the lab:\n\n3.1 Cloquet Polygon Map\n\n\n\nCloquet Polygon Map\n\n\n\n\n3.2 Cloquet Map\n\n\n\nCloquet Map\n\n\n\n\n3.3 Hugomap\n\n\n\nHugomap\n\n\n\n\n3.4 Wetlands Map\n\n\n\nWetlands Map",
    "crumbs": [
      "ArcGIS",
      "Lab 01: Introduction to ArcGIS and Basic Map Operations"
    ]
  },
  {
    "objectID": "6381Lab01.html#conclusion",
    "href": "6381Lab01.html#conclusion",
    "title": "Lab 01: Introduction to ArcGIS and Basic Map Operations",
    "section": "4 Conclusion",
    "text": "4 Conclusion\nThis lab provided an essential introduction to ArcGIS, offering practical experience in handling shapefiles and generating exportable map products. The skills developed in this lab are foundational for more advanced GIS operations.",
    "crumbs": [
      "ArcGIS",
      "Lab 01: Introduction to ArcGIS and Basic Map Operations"
    ]
  },
  {
    "objectID": "6381Lab10.html",
    "href": "6381Lab10.html",
    "title": "Lab 10: Remote Sensing Data Analysis",
    "section": "",
    "text": "In this lab, we explore the use of Landsat 9 imagery for remote sensing data analysis. We will focus on downloading, displaying, and analyzing Landsat data using ArcGIS Pro, including creating composite images and conducting change detection analysis.",
    "crumbs": [
      "ArcGIS",
      "Lab 10: Remote Sensing Data Analysis"
    ]
  },
  {
    "objectID": "6381Lab10.html#introduction",
    "href": "6381Lab10.html#introduction",
    "title": "Lab 10: Remote Sensing Data Analysis",
    "section": "",
    "text": "In this lab, we explore the use of Landsat 9 imagery for remote sensing data analysis. We will focus on downloading, displaying, and analyzing Landsat data using ArcGIS Pro, including creating composite images and conducting change detection analysis.",
    "crumbs": [
      "ArcGIS",
      "Lab 10: Remote Sensing Data Analysis"
    ]
  },
  {
    "objectID": "6381Lab10.html#objectives",
    "href": "6381Lab10.html#objectives",
    "title": "Lab 10: Remote Sensing Data Analysis",
    "section": "2 Objectives",
    "text": "2 Objectives\n\nLearn how to download and process Landsat 9 imagery.\nUnderstand the methods for displaying and analyzing remote sensing data in ArcGIS Pro.\nCreate composite images using multiple Landsat bands.\nPerform change detection analysis to assess land cover changes over time.",
    "crumbs": [
      "ArcGIS",
      "Lab 10: Remote Sensing Data Analysis"
    ]
  },
  {
    "objectID": "6381Lab10.html#tasks",
    "href": "6381Lab10.html#tasks",
    "title": "Lab 10: Remote Sensing Data Analysis",
    "section": "3 Tasks",
    "text": "3 Tasks\n\n3.1 1. Downloading Landsat Imagery\nUsing the Earth Explorer tool, download Landsat 9 imagery for a region of interest. For this lab, the target area is Dallas, Texas.\n\n\n3.2 2. Displaying Landsat Imagery in ArcGIS Pro\nLoad the downloaded Landsat 9 imagery into ArcGIS Pro and explore various methods for displaying and analyzing the data. Specifically, create a composite image using the different spectral bands provided by the Landsat dataset.\n\n\n3.3 3. Creating a Composite Image\nUtilize the geoprocessing tools in ArcGIS Pro to combine the individual Landsat bands into a single composite image. The composite image will allow us to visualize the area using different spectral bands and understand the various land cover features.\n\n\n3.4 4. Change Detection Analysis\nConduct a change detection analysis using Landsat imagery from 2014 and 2024 for the Dallas area. The goal is to identify land cover changes over the past decade. The change detection process will involve comparing specific spectral bands from the two different time periods.",
    "crumbs": [
      "ArcGIS",
      "Lab 10: Remote Sensing Data Analysis"
    ]
  },
  {
    "objectID": "6381Lab10.html#results",
    "href": "6381Lab10.html#results",
    "title": "Lab 10: Remote Sensing Data Analysis",
    "section": "4 Results",
    "text": "4 Results\n\n4.0.1 Map: Adding and Exploring Landsat Imagery in ArcGIS Pro\n\n\n\nAdding and Exploring Landsat Imagery in ArcGIS Pro\n\n\n\n\n4.0.2 Sceenshot: Composite Image\n\n\n\nComposite Image\n\n\n\n\n4.0.3 Map: Change Detection Analysis\n\n\n\nChange Detection",
    "crumbs": [
      "ArcGIS",
      "Lab 10: Remote Sensing Data Analysis"
    ]
  },
  {
    "objectID": "6381Lab10.html#conclusion",
    "href": "6381Lab10.html#conclusion",
    "title": "Lab 10: Remote Sensing Data Analysis",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nThe analysis performed in this lab demonstrates the capabilities of Landsat 9 imagery in remote sensing applications. By creating composite images and conducting change detection, we were able to visualize and quantify land cover changes in the Dallas area over the past decade. These techniques are crucial for monitoring environmental changes and informing decision-making processes.",
    "crumbs": [
      "ArcGIS",
      "Lab 10: Remote Sensing Data Analysis"
    ]
  },
  {
    "objectID": "6381Lab06.html",
    "href": "6381Lab06.html",
    "title": "Lab 06: Tables in ArcGIS",
    "section": "",
    "text": "This lab focuses on tabular data management in ArcGIS. It involves viewing, selecting, reordering, and updating tabular data. The lab uses the USCounties.shp data layer and the soils.shp data set for various tasks.",
    "crumbs": [
      "ArcGIS",
      "Lab 06: Tables in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab06.html#introduction",
    "href": "6381Lab06.html#introduction",
    "title": "Lab 06: Tables in ArcGIS",
    "section": "",
    "text": "This lab focuses on tabular data management in ArcGIS. It involves viewing, selecting, reordering, and updating tabular data. The lab uses the USCounties.shp data layer and the soils.shp data set for various tasks.",
    "crumbs": [
      "ArcGIS",
      "Lab 06: Tables in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab06.html#objectives",
    "href": "6381Lab06.html#objectives",
    "title": "Lab 06: Tables in ArcGIS",
    "section": "2 Objectives",
    "text": "2 Objectives\n\nPractice tabular data management in ArcGIS.\nLearn how to create and join tables.",
    "crumbs": [
      "ArcGIS",
      "Lab 06: Tables in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab06.html#tasks",
    "href": "6381Lab06.html#tasks",
    "title": "Lab 06: Tables in ArcGIS",
    "section": "3 Tasks",
    "text": "3 Tasks\n\n3.1 1. Selecting by Attribute\nExplore and select features using the Select by Attributes tool in ArcGIS. For example, create a map displaying burglary rates for each county and normalize these rates by the population.\n\n\n3.2 2. Creating and Joining Tables\nCreate a new table containing soil properties, then join this table with the soils data layer. The joined table will be used to create a layout showing soils by fertility class.",
    "crumbs": [
      "ArcGIS",
      "Lab 06: Tables in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab06.html#results",
    "href": "6381Lab06.html#results",
    "title": "Lab 06: Tables in ArcGIS",
    "section": "4 Results",
    "text": "4 Results\n\n4.1 High Population Counties with High Old/Young Ratios\n\n\n\nHigh Population Counties with High Old/Young Ratios\n\n\n\n\n4.2 Macon Country North Carolina Soil Fertility\n\n\n\nMacon Country North Carolina Soil Fertility\n\n\n\n\n4.3 US Counties Cow Density per Square Mile\n\n\n\nUS Counties Cow Density per Square Mile",
    "crumbs": [
      "ArcGIS",
      "Lab 06: Tables in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab06.html#conclusion",
    "href": "6381Lab06.html#conclusion",
    "title": "Lab 06: Tables in ArcGIS",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nThis lab provided hands-on experience with selecting attributes, managing tables, and joining data in ArcGIS. The ability to manipulate and display tabular data is crucial for effective GIS analysis.",
    "crumbs": [
      "ArcGIS",
      "Lab 06: Tables in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab07.html",
    "href": "6381Lab07.html",
    "title": "Lab 07: Spatial Selection in ArcGIS",
    "section": "",
    "text": "This lab introduces spatial selection techniques in ArcGIS, focusing on proximity and adjacency. You will learn how to import and manipulate tables, perform joins, and create summary statistics. The lab also emphasizes the importance of repeating tasks to master GIS skills.",
    "crumbs": [
      "ArcGIS",
      "Lab 07: Spatial Selection in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab07.html#introduction",
    "href": "6381Lab07.html#introduction",
    "title": "Lab 07: Spatial Selection in ArcGIS",
    "section": "",
    "text": "This lab introduces spatial selection techniques in ArcGIS, focusing on proximity and adjacency. You will learn how to import and manipulate tables, perform joins, and create summary statistics. The lab also emphasizes the importance of repeating tasks to master GIS skills.",
    "crumbs": [
      "ArcGIS",
      "Lab 07: Spatial Selection in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab07.html#objectives",
    "href": "6381Lab07.html#objectives",
    "title": "Lab 07: Spatial Selection in ArcGIS",
    "section": "2 Objectives",
    "text": "2 Objectives\n\nLearn to select features based on proximity and adjacency.\nPractice importing tables and performing joins.\nCreate maps that summarize spatial data using tables.",
    "crumbs": [
      "ArcGIS",
      "Lab 07: Spatial Selection in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab07.html#tasks",
    "href": "6381Lab07.html#tasks",
    "title": "Lab 07: Spatial Selection in ArcGIS",
    "section": "3 Tasks",
    "text": "3 Tasks\n\n3.1 1. Select by Proximity and Adjacency\n\nUse spatial selection tools to find features based on their proximity to other features.\nExplore the relationship between different geographic features by selecting adjacent polygons.\n\n\n\n3.2 2. Import Tables and Perform Joins\n\nImport an Excel table, summarize it, and then join it with a shapefile.\nLearn how to handle common issues like missing keys or multiple entries.",
    "crumbs": [
      "ArcGIS",
      "Lab 07: Spatial Selection in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab07.html#results",
    "href": "6381Lab07.html#results",
    "title": "Lab 07: Spatial Selection in ArcGIS",
    "section": "4 Results",
    "text": "4 Results\n\n4.1 US Corn Production by County\n\n\n\nUS Corn Production by County\n\n\n\n\n4.2 California County Income and Recreation Maps\n\n\n\nCalifornia County Income",
    "crumbs": [
      "ArcGIS",
      "Lab 07: Spatial Selection in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab07.html#conclusion",
    "href": "6381Lab07.html#conclusion",
    "title": "Lab 07: Spatial Selection in ArcGIS",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nThis lab provided hands-on experience with spatial selection and table manipulation in ArcGIS. The tasks involved selecting features based on proximity and adjacency, importing and joining tables, and creating maps that summarize spatial data. By completing these exercises, you’ve gained a deeper understanding of spatial relationships and how to use ArcGIS to analyze them.",
    "crumbs": [
      "ArcGIS",
      "Lab 07: Spatial Selection in ArcGIS"
    ]
  }
]